---
title: "Not just the alveolar trill, but all “r-like\" sounds are associated with
  roughness across languages, pointing to a more general link between sound and touch"
author: "Rémi Anselme, François Pellegrino and Dan Dediu"
date: "`r Sys.Date()`"
output:
  html_document:
    highlight: textmate
    toc: true
    toc_depth: 6
    toc_float: false
    theme: cerulean
    number_sections: true
  pdf_document: 
    toc: true
    toc_depth: 6
    latex_engine: xelatex
subtitle: Supplementary materials (full analysis report)
editor_options:
  chunk_output_type: console
bibliography: bibliography.bib
csl: "apa-6th-edition.csl"
---

<style>
caption, .caption {
color: #555555;
font-weight: bold;
font-size: 105%;
text-align: left}

a[hreflang]:before{}
</style>



<!---
    Code and data accompanying the paper the recoding of the original paper
    "Trilled /r/ is associated with roughness, linking sound and touch across
    spoken languages" by Winter et al. (2022), Scientific Reports, 
    DOI:10.1038/s41598-021-04311-7
    (C) 2022-2023 Rémi Anselme, Dan Dediu and François Pellegrino

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
--->

```{r setup, include=FALSE}
## Knitting options:
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE,                   # default code chunk options
                      fig.width=11, fig.height=6, fig.align="center", comment=NA, # default figure dimensions
                      fig.path="./figures/",                                      # save images to ./figures/
                      dpi=72, dev="jpeg",                                         # please set dpi=300 and comment out dev="jpeg" for high resolution but very big images
                      cache=TRUE, autodep=TRUE);                                  # cache chunks


## Load needed packages:

library(knitr);
library(dplyr);
library(magrittr);
library(tibble);
library(readr);
library(ggalluvial);
library(parallel);
library(brms);
library(bayestestR);
library(ggplot2);
library(gridExtra);
library(ggpubr);
library(sjPlot);
library(lmerTest);
library(piecewiseSEM);
library(stringr);
library(ape);

`%>%` <- magrittr::`%>%`;

if( !dir.exists("./cached") ) dir.create("./cached", showWarnings=FALSE, recursive=TRUE);

# Should we try to reduce the size of the resulting HTML document?
small_HTML <- FALSE;
small_PDF <- TRUE;

## For Bayesian regressions with brms (some might be different for particular models to avoid too few or too many iterations):
brms_ncores  <- max(detectCores(all.tests=TRUE, logical=FALSE), 4, na.rm=TRUE); # try to use multiple cores, if present
brms_iter    <- 10000; brms_warmup <- 2000; brms_thin <- 5; # burn-in, iterations and thinning
brms_control <- list(adapt_delta=0.999, max_treedepth=15); # control params to pass to Stan: avoid the "divergent transitions after warmup" and "max_treedepth" warnings
brms_ci      <- 0.89; brms_rope <- c(-0.01, 0.01); # 89% HDI and a tight ROPE around 0.0 [-0.01, 0.01]


# Figure and Table caption adapted from https://stackoverflow.com/questions/37116632/rmarkdown-html-number-figures: 
outputFormat = opts_knit$get("rmarkdown.pandoc.to"); # determine the output format of the document
if( is.null(outputFormat) ) outputFormat = ""; # probably not run within knittr
capTabNo = 1; capFigNo = 1; # figure and table caption numbering, for HTML do it manually
#Function to add the Table Number
capTab = function(x){
  if(outputFormat == 'html'){
    x = paste0("***Table ",capTabNo,".*** _",x,"_")
    capTabNo <<- capTabNo + 1
  }; x
}
#Function to add the Figure Number
capFig = function(x){
  if(outputFormat == 'html'){
    x = paste0("***Figure ",capFigNo,".*** _",x,"_")
    capFigNo <<- capFigNo + 1
  }; x
}

source("./from_winter2022/scripts/rough_helper.r"); # R code from @winter_trilled_2022


# Prepare maps for plotting:
world_map <- ggplot2::map_data("world") %>% 
  dplyr::filter(region != "Antarctica");

basic4map <- ggplot2::ggplot() + 
  ggplot2::coord_fixed() +
  ggplot2::xlab("") +
  ggplot2::ylab("");

base_world <- basic4map +
  ggplot2::geom_polygon(data=world_map,
                        ggplot2::aes(x=long,
                                     y=lat,
                                     group=group), 
                        colour="gray",
                        fill="gray") +
  ggplot2::theme(panel.background = ggplot2::element_rect(
    size = 0.5,
    linetype = "solid"),
    panel.grid.major = ggplot2::element_line(
      size = 0.5,
      linetype = 'solid',
      colour = "gray90"), 
    panel.grid.minor = ggplot2::element_line(
      size = 0.25,
      linetype = 'solid',
      colour = "gray90")) ;

rm(basic4map); # free up space
  
# colors for plotting:
r_col <- "#440154FF";
other_col <- "#FDE725FF";

world <- rnaturalearth::ne_countries(scale = "medium", returnclass = "sf");

theme_rough <- 
ggplot2::theme_classic() + 
  ggplot2::theme(legend.position = "none",
        legend.key.height = ggplot2::unit(2,"line"),
        legend.title = ggplot2::element_blank(),
        legend.text = ggplot2::element_text(size = 12),
        legend.background = ggplot2::element_rect(fill = "transparent"),
        strip.background = ggplot2::element_blank(),
        strip.text = ggplot2::element_text(size = 12, face = "bold"),
        panel.spacing = ggplot2::unit(2, "lines"),
        panel.border = ggplot2::element_blank(),
        plot.background = ggplot2::element_rect(fill = "transparent", colour = NA),
        panel.background = ggplot2::element_rect(fill = "transparent"),
        strip.text.y =ggplot2:: element_text(size = 12, hjust = 0),
        axis.text.x = ggplot2::element_text(size = 12, colour="black", face="bold"),
        axis.text.y = ggplot2::element_text(size = 12, colour="black"),
        axis.line = ggplot2::element_blank(),
        axis.ticks.x = ggplot2::element_blank(),
        axis.title = ggplot2::element_text(size = 12, face = "bold"),
        plot.title = ggplot2::element_text(size = 14, face = "bold"),
        plot.margin = ggplot2::unit(c(0.4,0.4,0.4,0.4),"cm"));



# Verbal interpretation of Bayes factors (BF):
BF_interpretation <- function(BF, model1_name="m1", model2_name="m2")
{
  if( BF > 100 )   return (paste0("extreme evidence for ",model1_name," against ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 30 )    return (paste0("very strong evidence for ",model1_name," against ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 10 )    return (paste0("strong evidence for ",model1_name," against ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 3 )     return (paste0("moderate evidence for ",model1_name," against ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 1 )     return (paste0("anecdotal evidence for ",model1_name," against ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF == 1 )    return (paste0("no evidence for ",model1_name," nor ",model2_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 0.33 )  return (paste0("anecdotal evidence for ",model2_name," against ",model1_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 0.10 )  return (paste0("moderate evidence for ",model2_name," against ",model1_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 0.033 ) return (paste0("strong evidence for ",model2_name," against ",model1_name, " (BF=",sprintf("%.3g",BF),")"));
  if( BF > 0.010 ) return (paste0("very strong evidence for ",model2_name," against ",model1_name, " (BF=",sprintf("%.3g",BF),")"));
  return (paste0("extreme evidence for ",model2_name," against ",model1_name, " (BF=",sprintf("%.3g",BF),")"));
}

# Here I hack brms' kfold code to make it run in parallel using good old mclapply instead of futures
# this avoid random crashes which seem to be due to future, but works only on *NIX (which, for me here, is not an issue)
# Adapted the code from https://github.com/paul-buerkner/brms/blob/master/R/loo.R and https://github.com/paul-buerkner/brms/blob/master/R/kfold.R
if( Sys.info()['sysname'] == "Windows" )
{
  # In Windows, fall back to the stadard implementation in brms:
  add_criterion_kfold_parallel <- function(model, K=10, chains=1)
  {
    return (add_criterion(model, criterion="kfold", K=K, chains=chains));
  }
} else
{
  # On anything else, try to use maclapply:
  add_criterion_kfold_parallel <- function(model, K=10, chains=1)
  {
    model <- restructure(model);
  
    mf <- model.frame(model); 
    attributes(mf)[c("terms", "brmsframe")] <- NULL;
    N <- nrow(mf);
    
    if( K > N ) return (model); # does not work in this case...
    
    fold_type <- "random"; folds <- loo::kfold_split_random(K, N);
    Ksub <- seq_len(K);
  
    kfold_results <- mclapply(Ksub, function(k) 
    {
      omitted <- predicted <- which(folds == k);
      mf_omitted <- mf[-omitted, , drop=FALSE];
      
      if( exists("subset_data2", envir=asNamespace("brms")) )
      {
        # Newer versions of brms:
        model_updated <- base::suppressWarnings(update(model, newdata=mf_omitted, data2=brms:::subset_data2(model$data2, -omitted), refresh=0, chains=chains));
        
        lppds <- log_lik(model_updated, newdata=mf[predicted, , drop=FALSE], newdata2=brms:::subset_data2(model$data2, predicted), 
                         allow_new_levels=TRUE, resp=NULL, combine=TRUE, chains=chains);
      } else if( exists("subset_autocor", envir=asNamespace("brms")) )
      {
        # Older versions of brms:
        model2 <- brms:::subset_autocor(model, -omitted, incl_car=TRUE);
        model_updated <- base::suppressWarnings(update(model2, newdata=mf_omitted, refresh=0, chains=chains));
        
        lppds <- log_lik(model_updated, newdata=mf[predicted, , drop=FALSE], allow_new_levels=TRUE, resp=NULL, combine=TRUE, chains=chains);
      } else
      {
        stop("Unknown version of brms!");
      }
  
      return (list("obs_order"=predicted, "lppds"=lppds));
    }, mc.cores=ifelse(exists("brms_ncores"), brms_ncores, detectCores()));
    
    # Put them back in the form expected by the the following unmodifed code:
    obs_order <- lapply(kfold_results, function(x) x$obs_order);
    lppds     <- lapply(kfold_results, function(x) x$lppds);
    
    elpds <- brms:::ulapply(lppds, function(x) apply(x, 2, brms:::log_mean_exp))
    # make sure elpds are put back in the right order
    elpds <- elpds[order(unlist(obs_order))]
    elpd_kfold <- sum(elpds)
    se_elpd_kfold <- sqrt(length(elpds) * var(elpds))
    rnames <- c("elpd_kfold", "p_kfold", "kfoldic")
    cnames <- c("Estimate", "SE")
    estimates <- matrix(nrow = 3, ncol = 2, dimnames = list(rnames, cnames))
    estimates[1, ] <- c(elpd_kfold, se_elpd_kfold)
    estimates[3, ] <- c(-2 * elpd_kfold, 2 * se_elpd_kfold)
    out <- brms:::nlist(estimates, pointwise = cbind(elpd_kfold = elpds))
    atts <- brms:::nlist(K, Ksub, NULL, folds, fold_type)
    attributes(out)[names(atts)] <- atts
    out <- structure(out, class = c("kfold", "loo"))
    
    attr(out, "yhash") <- brms:::hash_response(model, newdata=NULL, resp=NULL);
    attr(out, "model_name") <- "";
    
    model$criteria$kfold <- out;
    model;
  }
}

# Bayesian fit indices for a given model:
brms_fit_indices <- function(model, indices=c("bayes_R2", "loo", "waic", "kfold"), K=10, verbose=TRUE, do.parallel=TRUE)
{
  if( "bayes_R2" %in% indices )
  {
    if( verbose) cat("R^2...\n");
    #attr(model, "R2") <- bayes_R2(model); 
    model <- add_criterion(model, "bayes_R2"); 
  } else
  {
    # Remove the criterion (if already there):
    if( !is.null(model$criteria) && "bayes_R2" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "bayes_R2") ]] <- NULL;
  }
  
  if( "loo" %in% indices )
  {
    if( verbose) cat("LOO...\n");
    model <- add_criterion(model, "loo"); 
  } else
  {
    # Remove the criterion (if already there):
    if( !is.null(model$criteria) && "loo" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "loo") ]] <- NULL;
  }
  
  if( "waic" %in% indices )
  {
    if( verbose) cat("WAIC...\n");
    model <- add_criterion(model, "waic"); 
  } else
  {
    # Remove the criterion (if already there):
    if( !is.null(model$criteria) && "waic" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "waic") ]] <- NULL;
  }
  
  if( "kfold" %in% indices )
  {
    if( verbose) cat(paste0("KFOLD (K=",K,")...\n"));
    model1 <- NULL;
    if( !do.parallel )
    {
      try(model1 <- add_criterion(model, "kfold", K=K, chains=1), silent=TRUE);
    } else
    {
      try(model1 <- add_criterion_kfold_parallel(model, K=K, chains=1), silent=TRUE);
    }
    if( !is.null(model1) )
    {
      model <- model1;
    } else
    {
      # Remove the criterion (if already there):
      if( !is.null(model$criteria) && "kfold" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "kfold") ]] <- NULL;
    }
  } else
  {
    # Remove the criterion (if already there):
    if( !is.null(model$criteria) && "kfold" %in% names(model$criteria) ) model$criteria[[ which(names(model$criteria) == "kfold") ]] <- NULL;
  }

  gc();
  
  return (model);
}

# Bayesian model comparison:
#model1 <- b_uvbm__blue
#model2 <- b_popsize__blue
brms_compare_models <- function(model1, model2, name1=NA, name2=NA, bayes_factor=TRUE, print_results=TRUE)
{
  if( !is.null(model1$criteria) && "bayes_R2" %in% names(model1$criteria) && !is.null(model1$criteria$bayes_R2) &&
      !is.null(model2$criteria) && "bayes_R2" %in% names(model2$criteria) && !is.null(model2$criteria$bayes_R2) )
  {
    R2_1_2 <- (mean(model1$criteria$bayes_R2) - mean(model2$criteria$bayes_R2));
  } else
  {
    R2_1_2 <- NA;
  }
  
  if( bayes_factor )
  {
    invisible(capture.output(bf_1_2 <- brms::bayes_factor(model1, model2)$bf));
    bf_interpret_1_2 <- BF_interpretation(bf_1_2, ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")); 
  }
  else
  {
    bf_1_2 <- NULL; bf_interpret_1_2 <- NA;
  }
  
  if( !is.null(model1$criteria) && "loo" %in% names(model1$criteria) && !is.null(model1$criteria$loo) &&
      !is.null(model2$criteria) && "loo" %in% names(model2$criteria) && !is.null(model2$criteria$loo) )
  {
    loo_1_2 <- loo_compare(model1, model2, criterion="loo", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
  } else
  {
    loo_1_2 <- NA;
  }
  
  if( !is.null(model1$criteria) && "waic" %in% names(model1$criteria) && !is.null(model1$criteria$waic) &&
      !is.null(model2$criteria) && "waic" %in% names(model2$criteria) && !is.null(model2$criteria$waic) )
  {
    waic_1_2 <- loo_compare(model1, model2, criterion="waic", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
    mw_1_2 <- model_weights(model1, model2, weights="waic", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
  } else
  {
    waic_1_2 <- NA; 
    mw_1_2 <- NA;
  }
  
  if( !is.null(model1$criteria) && "kfold" %in% names(model1$criteria) && !is.null(model1$criteria$kfold) &&
      !is.null(model2$criteria) && "kfold" %in% names(model2$criteria) && !is.null(model2$criteria$kfold) )
  {
    kfold_1_2 <- loo_compare(model1, model2, criterion="kfold", model_names=c(ifelse(!is.na(name1), name1, "model1"), ifelse(!is.na(name2), name2, "model2")));
  } else
  {
    kfold_1_2 <- NA;
  }
  
  if( print_results )
  {
    cat(paste0("\nComparing models '",ifelse(!is.na(name1), name1, "model1"),"' and '",ifelse(!is.na(name2), name2, "model2"),"':\n\n"));
    cat(paste0("\ndelta R^2 = ",sprintf("%.1f%%",100*R2_1_2),"\n\n"));
    cat(bf_interpret_1_2,"\n\n");
    cat("\nLOO:\n"); print(loo_1_2);
    cat("\nWAIC:\n"); print(waic_1_2);
    cat("\nKFOLD:\n"); print(kfold_1_2);
    cat("\nModel weights (WAIC):\n"); print(mw_1_2);
    cat("\n");
  }
  
  gc();
  
  return (list("R2"=R2_1_2, "BF"=bf_1_2, "BF_interpretation"=bf_interpret_1_2, "LOO"=loo_1_2, "WAIC"=waic_1_2, "KFOLD"=kfold_1_2, "model_weights_WAIC"=mw_1_2));
}

# print model comparisons
.print.model.comparison <- function(a=NULL, a.names=NULL, b=NULL) # a is the anova and b is the Bayesian comparison (only one can be non-NULL), a.names are the mappings between the inner and user-friendly model names
{
  # ANOVA:
  if( !is.null(a) )
  {
    a <- as.data.frame(a);
    if( !is.null(a.names) )
    {
      if( length(a.names) != nrow(a) || !all(names(a.names) %in% rownames(a)) )
      {
        stop("a.names do not correspond the anova model names!");
        return (NULL);
      }
      rownames(a) <- a.names[rownames(a)];
    }
    i <- which.min(a$AIC);
    s.a <- sprintf("%s %s %s: ΔAIC=%.1f, ΔBIC=%.1f", 
                   rownames(a)[i], 
                   ifelse((!is.na(a[2,"Pr(>Chisq)"]) && a[2,"Pr(>Chisq)"] <0.05) || (abs(a$AIC[1] - a$AIC[2]) > 3), ">", "≈"),
                   rownames(a)[3-i],
                   abs(a$AIC[1] - a$AIC[2]), 
                   abs(a$BIC[1] - a$BIC[2]));
    if( !is.na(a[2,"Pr(>Chisq)"]) )
    {
      s.a <- paste0(s.a,
                    sprintf(", *p*=%s", scinot(a[2,"Pr(>Chisq)"])));
    }
    
    # return value:
    return (s.a);
  }
  
  # Bayesian comparison:
  if( !is.null(b) )
  {
    s.b <- sprintf("BF: %s, ΔLOO(%s %s %s)=%.1f (%.1f), ΔWAIC(%s %s %s)=%.1f (%.1f), ΔKFOLD(%s %s %s)=%.1f (%.1f)",
                   # BF:
                   b$BF_interpretation, 
                   # LOO:
                   rownames(b$LOO)[1],
                   ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 4 || abs(b$LOO[1,1]-b$LOO[2,1]) < b$LOO[2,2], "≈", ifelse(abs(b$LOO[1,1]-b$LOO[2,1]) < 2*b$LOO[2,2], ">", ">>")),
                   rownames(b$LOO)[2], 
                   abs(b$LOO[1,1]-b$LOO[2,1]), b$LOO[2,2], 
                   # WAIC:
                   rownames(b$WAIC)[1], 
                   ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 4 || abs(b$WAIC[1,1]-b$WAIC[2,1]) < b$WAIC[2,2], "≈", ifelse(abs(b$WAIC[1,1]-b$WAIC[2,1]) < 2*b$WAIC[2,2], ">", ">>")), 
                   rownames(b$WAIC)[2], 
                   abs(b$WAIC[1,1]-b$WAIC[2,1]), b$WAIC[2,2],
                   # KFOLD:
                   rownames(b$KFOLD)[1], 
                   ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 4 || abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < b$KFOLD[2,2], "≈", ifelse(abs(b$KFOLD[1,1]-b$KFOLD[2,1]) < 2*b$KFOLD[2,2], ">", ">>")), 
                   rownames(b$KFOLD)[2], 
                   abs(b$KFOLD[1,1]-b$KFOLD[2,1]), b$KFOLD[2,2]);
    
    # return value:
    return (s.b);
  }
}

```


# Introduction

This is a reanalysis of @winter_trilled_2022 using a manual recoding of all the languages in their sample: for details about the recoding, please see Rémi Anselme's PhD thesis [@anselme_representation_2022] and the associated [GitHub repository](https://github.com/ranselme/Ressources_supplementaires_These), especially [Chapter 5 ("Chapitre 5")](https://github.com/ranselme/Ressources_supplementaires_These/tree/main/Chapitre_5), where all the details (and a preliminary analysis) are given.
Please note that one extra step is needed, namely to run the `Rmarkdown` script `IE_recoding_adapted.Rmd` (which is adapted from the original `IE_recoding.Rmd` in the *ranselme/Ressources_supplementaires_These* `GitHub` repository to fit this project) to generate the recoding of the Indo-European (IE) languages as well (for easiness, the pre-compiled `HTML` version of this script is included as well -- please note that this document is mixed English/French)... 

Here, we simply use the results of this recoding as available in the directories and files shown below:

|  Original location relative to the root of [Rémi Anselme's GitHub repository (Chapitre 5)](https://github.com/ranselme/Ressources_supplementaires_These)  | Location relative to this `Rmarkdown` document | Description |
|--------------------------------------|--------------------------------|------------------------------|
| [`./donnees_winter2022/final_data/cross_linguistic.csv`](https://github.com/ranselme/Ressources_supplementaires_These/blob/main/Chapitre_5/donnees_winter2022/final_data/cross_linguistic.csv) | `./data/cross_linguistic.csv` | original data of @winter_trilled_2022 as a comma-separated quoted `CVS` file |
| [`./data_replication/rough_r_data.csv`](https://github.com/ranselme/Ressources_supplementaires_These/blob/main/Chapitre_5/data_replication/rough_r_data.csv) | `./data/rough_r_data.csv` | the recoded data as a comma-separated quoted `CVS` file |
| -- | `./data/rough_r_data_IE.csv` | the recoded data for the Indo-European languages as a comma-separated quoted `CVS` file (generated by running `IE_recoding_adapted.Rmd`) |
| [`./models/xling_brm_rs_logistic_mod_r.rds`](https://github.com/ranselme/Ressources_supplementaires_These/blob/main/Chapitre_5/models/xling_brm_rs_logistic_mod_r.rds) | `./models/xling_brm_rs_logistic_mod_r.rds` | the originally fitted model for languages with trilled /r/ (as an `R` serialized object saved with `saveRDS()`) |
| [`./models/xling_nt_brm_rs_logistic_mod_r.rds`](https://github.com/ranselme/Ressources_supplementaires_These/blob/main/Chapitre_5/models/xling_nt_brm_rs_logistic_mod_r.rds) | `./models/xling_nt_brm_rs_logistic_mod_r.rds` | as above for languages without a trilled /r/ |

The code here is based on, and extends Rémi's own code in [Chapter 5 ("Chapitre 5")](https://github.com/ranselme/Ressources_supplementaires_These/tree/main/Chapitre_5), which is, in turn, based on the original code accompanying @winter_trilled_2022.
For reproductibility and speed, we also cached the results of the main Bayesian models fitted as `R` serialized objects (saved using `save()`) in the folder `./cached`, but these can be easily refitted by simply deleting the `.RData` files there.
Please note that, also for reproductibility, as in the original, we always set the random number generator seed before fitting a model using `set.seed(314)`.

```{r}
# Check if IE_recoding_adapted.Rmd was already ran or not:
if( !file.exists("./data/rough_r_data_IE.csv") )
{
  stop(paste0("Please run first the ./IE_recoding_adapted.Rmd script to generate the ./data/rough_r_data_IE.csv file!"));
}
```

```{r results='asis'}
if( small_HTML ) cat("***N.B.*: please note that, in order to reduce the size of the resulting `HTML` document, some of the plots were not included here, being replced with a generic placeholder; please consult the full report in the [GitHub repository](https://github.com/ddediu/r-roughness-recoding).**");
if( small_PDF ) cat("***N.B.*: please note that, first, as this document's intended format is `HTML`, its conversion to `PDF` might result in some typographic issues, and, second, that in order to reduce its size the quality of the images and plots was degraded (but is still decent); please consult the full report in the [GitHub repository https://github.com/ddediu/r-roughness-recoding](https://github.com/ddediu/r-roughness-recoding).**");
```


# Data

```{r load the revised data, include=FALSE}
# Load the recoded data:
rough_r_data    <- read.csv("./data/rough_r_data.csv"); # excluding the IE languages (the original)
rough_r_data_ie <- read.csv("./data/rough_r_data_IE.csv"); # including our recoding for the IE languages


# Excluding our recoding of the IE languages, as in the original:
rough_r_data %>% 
  dplyr::select(Language,revision,Trill) %>% 
  dplyr::filter(!is.na(revision)) %>% 
  dplyr::group_by(Trill) %>% 
  dplyr::distinct() %>% dplyr::select(revision) %>% 
  table() %>% as.data.frame() -> table_changes;

# Fix family and branch names:
rough_r_data$Family[ rough_r_data$Family == "Cams��" ] <- "Camsá";
rough_r_data$Family[ rough_r_data$Family == "Tuc��noan" ] <- "Tucanoan";
rough_r_data$Family[ rough_r_data$Family == "Choc�_" ] <- "Chocoan";
rough_r_data$Family[ rough_r_data$Family == "Hot�_" ] <- "Hoti";
rough_r_data$Family[ rough_r_data$Family == "Cof��n" ] <- "Cofán";
rough_r_data$Family[ rough_r_data$Family == "Moset��n" ] <- "Mosetén";
rough_r_data$Family[ rough_r_data$Family == "Truma�_" ] <- "Trumai";
rough_r_data$Family[ rough_r_data$Family == "Atacame��o" ] <- "Atacameño";
rough_r_data$Family[ rough_r_data$Family == "East Bird���s Head" ] <- "East Bird's Head";
rough_r_data$Branch[ rough_r_data$Branch == "Tupi-Guaran�_" ] <- "Tupi-Guarani";
rough_r_data$Branch[ rough_r_data$Branch == "Karaj��" ] <- "Karajá";
rough_r_data$Branch[ rough_r_data$Branch == "South Bird���s Head" ] <- "South Bird's Head";

# Kinds of changes due to our recoding:
table_changes_2 <- table_changes %>% 
         dplyr::mutate(Trill = ifelse(Trill=="yes","Trill","Other"),
                       revision = dplyr::case_when(revision == "ERROR" ~ "Error",
                                                   revision == "OUT" ~ "Contrast",
                                                   revision == "other" ~ "OTHER",
                                                   revision == "trilled" ~ "TRILL",
                                                   revision == "NA_" ~ "NA"),
                       revision = ifelse(is.na(revision),"NA",revision),
                       Data = ifelse(revision %in% c("TRILL","OTHER"),"Included","Excluded"));
table_changes_2$revision <- factor(table_changes_2$revision,levels = c("OTHER","Contrast","Error","NA","TRILL"));

data_R_revision_2 <- rough_r_data %>% 
                        dplyr::select(Language,Latitude,Longitude,revision,Trill) %>% 
                        dplyr::mutate(revision = ifelse(revision=="trilled","TRILL",
                                                        ifelse(revision=="other","OTHER","OLD")),
                                      Data = ifelse(revision%in%c("TRILL","OTHER"),"NEW","OLD")) %>% 
                        dplyr::distinct();
data_R_revision_2$revision <- factor(data_R_revision_2$revision,levels = c("OTHER","TRILL","OLD"));


# Load the original @winter_trilled_2022 results:
xling <- read.csv("./data/cross_linguistic.csv") %>%
  dplyr::filter(Meaning %in% c("rough","smooth"),
         Family!="Indo-European"); # do not include IE

# Fix family and branch names:
xling$Family[ xling$Family == "Cams\x92\x8d" ] <- "Camsá";
xling$Family[ xling$Family == "Tuc\x92\x8dnoan" ] <- "Tucanoan";
xling$Family[ xling$Family == "Choc\x92_" ] <- "Chocoan";
xling$Family[ xling$Family == "Hot\x92_" ] <- "Hoti";
xling$Family[ xling$Family == "Cof\x92\x8dn" ] <- "Cofán";
xling$Family[ xling$Family == "Moset\x92\xa9n" ] <- "Mosetén";
xling$Family[ xling$Family == "Truma\x92_" ] <- "Trumai";
xling$Family[ xling$Family == "Atacame\x92\xb1o" ] <- "Atacameño";
xling$Family[ xling$Family == "East Bird\x8a\x97\xc8s Head" ] <- "East Bird's Head";
xling$Branch[ xling$Branch == "Tupi-Guaran\x92_" ] <- "Tupi-Guarani";
xling$Branch[ xling$Branch == "Karaj\x92\x8d" ] <- "Karajá";
xling$Branch[ xling$Branch == "South Bird\x8a\x97\xc8s Head" ] <- "South Bird's Head";

xling$Meaning <- paste0("‘", xling$Meaning, "’");
xling$Meaning.f <- factor(xling$Meaning)#, levels=c("‘smooth’", "‘rough’"));
# only Google TRS data for Basque:
xling <- dplyr::filter(xling, !(Language=="Basque" & Dataset=="CLICS"));

# some languages happen to have more than one rough / smooth words (very small minority!)
# reduce to single data point via majority rule:
xling_single <- xling %>%
  dplyr::filter(Trill=="yes") %>%
  dplyr::group_by(Language,Meaning.f) %>%
  dplyr::summarise(r = as.logical(round(mean(r))),
            Longitude=Longitude[1],
            Latitude=Latitude[1]) %>%
  dplyr::ungroup();

data_R_revision <- rough_r_data; # rename our recoded data 

xling_revision <- data_R_revision %>%
  dplyr::filter(Meaning %in% c("rough","smooth"),
         Family!="Indo-European") %>% 
  dplyr::mutate(Trill = dplyr::case_when(revision == "trilled" ~ "yes",
                                         revision == "other" ~ "no",
                                         revision %in% c("OUT","NA") ~ "OUT")) %>% 
  dplyr::filter(Trill != "OUT");

xling_revision$Meaning <- paste0("‘", xling_revision$Meaning, "’");
xling_revision$Meaning.f <- factor(xling_revision$Meaning)#, levels=c("‘smooth’", "‘rough’"));

# some languages happen to have more than one rough / smooth words (very small minority!)
# reduce to single data point via majority rule:
xling_single_revision <- xling_revision %>%
  dplyr::filter(Trill=="yes") %>%
  dplyr::group_by(Language,Meaning.f) %>%
  dplyr::summarise(r = as.logical(round(mean(r))),
            Longitude=Longitude[1],
            Latitude=Latitude[1]) %>%
  dplyr::ungroup();




# Including our recoding of the IE languages as well:
rough_r_data_ie %>% 
  dplyr::select(Language,revision,Trill) %>% 
  dplyr::filter(!is.na(revision)) %>% 
  dplyr::group_by(Trill) %>% 
  dplyr::distinct() %>% dplyr::select(revision) %>% 
  table() %>% as.data.frame() -> table_changes_ie;

# Fix family and branch names:
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Cams��" ] <- "Camsá";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Tuc��noan" ] <- "Tucanoan";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Choc�_" ] <- "Chocoan";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Hot�_" ] <- "Hoti";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Cof��n" ] <- "Cofán";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Moset��n" ] <- "Mosetén";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Truma�_" ] <- "Trumai";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "Atacame��o" ] <- "Atacameño";
rough_r_data_ie$Family[ rough_r_data_ie$Family == "East Bird���s Head" ] <- "East Bird's Head";
rough_r_data_ie$Branch[ rough_r_data_ie$Branch == "Tupi-Guaran�_" ] <- "Tupi-Guarani";
rough_r_data_ie$Branch[ rough_r_data_ie$Branch == "Karaj��" ] <- "Karajá";
rough_r_data_ie$Branch[ rough_r_data_ie$Branch == "South Bird���s Head" ] <- "South Bird's Head";

# Kinds of changes due to our recoding:
table_changes_2_ie <- table_changes_ie %>% 
         dplyr::mutate(Trill = ifelse(Trill=="yes","Trill","Other"),
                       revision = dplyr::case_when(revision == "ERROR" ~ "Error",
                                                   revision == "OUT" ~ "Contrast",
                                                   revision == "other" ~ "OTHER",
                                                   revision == "trilled" ~ "TRILL",
                                                   revision == "NA_" ~ "NA"),
                       revision = ifelse(is.na(revision),"NA",revision),
                       Data = ifelse(revision %in% c("TRILL","OTHER"),"Included","Excluded"));
table_changes_2_ie$revision <- factor(table_changes_2_ie$revision,levels = c("OTHER","Contrast","Error","NA","TRILL"));

data_R_revision_2_ie <- rough_r_data_ie %>% 
                        dplyr::select(Language,Latitude,Longitude,revision,Trill) %>% 
                        dplyr::mutate(revision = ifelse(revision=="trilled","TRILL",
                                                        ifelse(revision=="other","OTHER","OLD")),
                                      Data = ifelse(revision%in%c("TRILL","OTHER"),"NEW","OLD")) %>% 
                        dplyr::distinct();
data_R_revision_2_ie$revision <- factor(data_R_revision_2_ie$revision,levels = c("OTHER","TRILL","OLD"));

data_R_revision_ie <- rough_r_data_ie; # rename our recoded data 

xling_revision_ie <- data_R_revision_ie %>%
  dplyr::filter(Meaning %in% c("rough","smooth"),
         Family!="Indo-European") %>% 
  dplyr::mutate(Trill = dplyr::case_when(revision == "trilled" ~ "yes",
                                         revision == "other" ~ "no",
                                         revision %in% c("OUT","NA") ~ "OUT")) %>% 
  dplyr::filter(Trill != "OUT");

xling_revision_ie$Meaning <- paste0("‘", xling_revision_ie$Meaning, "’");
xling_revision_ie$Meaning.f <- factor(xling_revision_ie$Meaning)#, levels=c("‘smooth’", "‘rough’"));

# some languages happen to have more than one rough / smooth words (very small minority!)
# reduce to single data point via majority rule:
xling_single_revision_ie <- xling_revision_ie %>%
  dplyr::filter(Trill=="yes") %>%
  dplyr::group_by(Language,Meaning.f) %>%
  dplyr::summarise(r = as.logical(round(mean(r))),
            Longitude=Longitude[1],
            Latitude=Latitude[1]) %>%
  dplyr::ungroup();
```

As a reminder, the original analysis of @winter_trilled_2022 excluded the IE languages, left aside for a separate analysis.
Nevertheless, we also recoded the IE languages but we do a exact replication of the original @winter_trilled_2022 excluding them, as well as an extended analysis that does include them.


## Excluding the Indo-European languages

The original analysis of @winter_trilled_2022  included `r sum(table_changes$Freq)` langues, as shown in the figure below:

```{r fig.width=10, fig.height=7, fig.cap=capFig("The languages included in the original analysis of Winter et al., divided into those coded as 'TRILL' and those coded 'OTHER' (the Indo-European languages were marked as not included).")}
base_world + 
  ggplot2::geom_point(data =  data_R_revision_2 %>% dplyr::filter(Data=="OLD"),
                      ggplot2::aes(x=Longitude, y=Latitude, shape=Data), fill="red",
             size=2, alpha=0.5)+
  ggplot2::geom_point(data =  data_R_revision_2 %>% dplyr::filter(revision!="OLD"),
                      ggplot2::aes(x=Longitude, y=Latitude, fill=revision, shape=Data),
             size=2, alpha=0.5) +
  ggplot2::scale_fill_viridis_d(name = "Coded as", labels=c("other", "trill")) +
  ggplot2::scale_shape_manual(values=c(21, 24),
                              name="Included?",
                              labels=c("yes", "no")) +
  ggplot2::ggtitle(NULL) + 
  ggplot2::theme(legend.position="bottom") +
  ggplot2::guides(fill=ggplot2::guide_legend(override.aes=list(shape = 21))) + 
  NULL;
```

Of these, we have kept, after recoding, only `r sum(table_changes[table_changes$revision=="other",]$Freq) + sum(table_changes[table_changes$revision=="trilled",]$Freq)`.

```{r fig.width=10, fig.height=7, fig.cap=capFig("The languages included in the recoded dataset, divided into those coded as 'trills' and those coded 'other' (the colors are consistent with those in the previous figure)."), include=!small_HTML}
d <- dplyr::filter(rough_r_data, !is.na(revision) & revision=="trilled" | revision=="other") %>% 
     dplyr::select(Longitude,Latitude,revision) %>% dplyr::distinct(); # no doubled entries in the table

base_world + 
  ggplot2::geom_point(data =  d,
                      ggplot2::aes(x=Longitude, y=Latitude, fill=revision), shape=21,
             size=2, alpha=0.5) +
  ggplot2::scale_fill_viridis_d(name = "Recoded as", labels=c("other", "trill")) +
  ggplot2::ggtitle(NULL) + 
  ggplot2::theme(legend.position="bottom") +
  NULL;
```

They are distributed in `r nrow(unique(dplyr::filter(rough_r_data, !is.na(revision) & revision=="trilled" | revision=="other") %>%  dplyr::select(Family)))` language families, with the first 10 largest families being:

```{r}
kable(sort(table(dplyr::filter(unique(dplyr::select(rough_r_data,Language,Family)),Family!="Indo-European")$Family), decreasing=TRUE)[1:10], 
      col.names=c("Family", "# languages"), 
      caption=capTab("The largest 10 families in our recoded dataset."));
```

and distributed areally:

```{r}
kable(table(dplyr::filter(unique(dplyr::select(rough_r_data,Language,Area,Family)),Family!="Indo-European")$Area), 
      col.names=c("Area", "# languages"), 
      caption=capTab("The areas in our recoded dataset."));
```

The following figure summarizes the changes in language coding following our reanalysis:

```{r fig.width=7, fig.height=8, fig.cap=capFig("Figure showing the effects of our recoding of the languages: the left-most side shows the original coding in Winter et al., in the middle are our recoded values, and, on the gith, the languages included/excluded from our reanalysis.")}
ggplot2::ggplot(data = table_changes_2,
       ggplot2::aes(axis1 = Trill, axis2 = revision, axis3 = Data, y = Freq)) +
  ggalluvial::geom_alluvium(ggplot2::aes(fill = revision)) +
  ggalluvial::geom_stratum(fill="grey90") +
  ggplot2::geom_text(stat = ggalluvial::StatStratum,
            ggplot2::aes(label = tolower(ggplot2::after_stat(stratum)))) +
  ggplot2::scale_x_discrete(limits = c("Survey", "Response"),
                   expand = c(0.15, 0.05)) +
  ggplot2::scale_fill_manual(values=c("OTHER"="gray50", "Error"="red", "TRILL"="yellow", "Contrast"="blue","NA"="black"), 
                             labels=c("OTHER"="other", "Error"="error", "TRILL"="trill", "Contrast"="contrast","NA"="na"),
                             name="Recoding") +
  ggplot2::theme_void() +
  NULL;
```

We show below a comparison between the distribution of the trilled /r/ in the words 'rough' and 'smooth' in the original dataset of @winter_trilled_2022 and in our recoded dataset:

```{r fig.width=2*6, fig.height=4, fig.cap=capFig("The distribution of the trilled /r/ (present, yellow, vs. not, gray) in the words 'rough' (left) and 'smooth' (right) among the languages in the original dataset of Winter et al. using their original coding (top) and our recoded dataset (bottom). The languages included differ between the four panel, as explained in the text. *N.B.* the Indo-European languages are not included."), fig.show="hold", out.width="100%"}
base_world +
  ggplot2::geom_sf(size=0.2, col="white", fill="lightgrey") +
  ggplot2::coord_sf(xlim = c(-180, 180), ylim = c(-60, 80), datum=NA) +
  ggplot2::geom_point(data = xling_single, ggplot2::aes(x = Longitude, y = Latitude, fill = r, group = NA),
             alpha = 0.65, size = 2.5,
             col="black", pch=21, stroke=0.75,
             position = ggplot2::position_jitter(width=2.5,height=2.5,seed=1)) +
  ggplot2::facet_grid(~Meaning.f) +
  ggplot2::scale_fill_viridis_d(labels=c("no /r/", "contains /r/")) +
  ggplot2::labs(title = "The original coding") +
  theme_rough +
  ggplot2::theme(
    legend.position = "none",
    axis.title = ggplot2::element_blank(),
    axis.text = ggplot2::element_blank(),
    axis.line = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    plot.margin = ggplot2::unit(c(0.1,0.4,-0.4,0.4),"cm"),
    panel.spacing = ggplot2::unit(0, "lines")) +
  NULL;

base_world +
  ggplot2::geom_sf(size=0.2, col="white", fill="lightgrey") +
  ggplot2::coord_sf(xlim = c(-180, 180), ylim = c(-60, 80), datum=NA) +
  ggplot2::geom_point(data = xling_single_revision, ggplot2::aes(x = Longitude, y = Latitude, fill = r, group = NA),
             alpha = 0.65, size = 2.5,
             col="black", pch=21, stroke=0.75,
             position = ggplot2::position_jitter(width=2.5,height=2.5,seed=1)) +
  ggplot2::facet_grid(~Meaning.f) +
  ggplot2::scale_fill_viridis_d(labels=c("no /r/", "contains /r/")) +
  ggplot2::labs(title = "The recoding") +
  theme_rough +
  ggplot2::theme(
    legend.position = "bottom",
    axis.title = ggplot2::element_blank(),
    axis.text = ggplot2::element_blank(),
    axis.line = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    plot.margin = ggplot2::unit(c(0.1,0.4,-0.4,0.4),"cm"),
    panel.spacing = ggplot2::unit(0, "lines")) + 
  NULL;
```

Values for *revision*:

- `NA`: languages not included in the original analysis (Indo-European languages, etc)
- "NA_": undecidable given the available sources
- "trilled": languages with a single rhotic and that is a trill
- "other": languages without a contrast involving a trill
- "OUT": languages with a contrast involving a trill that in the original paper are supposedly excluded but, in fact, are included in the analysis
- "ERROR": wrong code for a language


## Recoding also the Indo-European languages

```{r fig.width=10, fig.height=7, fig.cap=capFig("The languages included in the original analysis of Winter et al., divided into those coded as 'TRILL' and those coded 'OTHER', including the IE languages."), include=!small_HTML}
base_world + 
  ggplot2::geom_point(data =  data_R_revision_2_ie %>% dplyr::filter(Data=="OLD"),
                      ggplot2::aes(x=Longitude, y=Latitude, shape=Data), fill="red",
             size=2, alpha=0.5)+
  ggplot2::geom_point(data =  data_R_revision_2_ie %>% dplyr::filter(revision!="OLD"),
                      ggplot2::aes(x=Longitude, y=Latitude, fill=revision, shape=Data),
             size=2, alpha=0.5) +
  ggplot2::scale_fill_viridis_d(name = "Coded as", labels=c("other", "trill")) +
  ggplot2::scale_shape_manual(values=c(21, 24),
                              name="Included?",
                              labels=c("yes", "no")) +
  ggplot2::ggtitle(NULL) + 
  ggplot2::theme(legend.position="bottom") +
  ggplot2::guides(fill=ggplot2::guide_legend(override.aes=list(shape = 21))) + 
  NULL;
```

After recoding, we kept `r sum(table_changes_ie[table_changes_ie$revision=="other",]$Freq) + sum(table_changes_ie[table_changes_ie$revision=="trilled",]$Freq)` languages.

```{r fig.width=10, fig.height=7, fig.cap=capFig("The languages included in the recoded dataset, divided into those coded as 'trills' and those coded 'other' (the colors are consistent with those in the previous figure)."), include=!small_HTML}
d <- dplyr::filter(rough_r_data_ie, !is.na(revision) & revision=="trilled" | revision=="other") %>% 
     dplyr::select(Longitude,Latitude,revision) %>% dplyr::distinct(); # no doubled entries in the table

base_world + 
  ggplot2::geom_point(data =  d,
                      ggplot2::aes(x=Longitude, y=Latitude, fill=revision), shape=21,
             size=2, alpha=0.5) +
  ggplot2::scale_fill_viridis_d(name = "Recoded as", labels=c("other", "trill")) +
  ggplot2::ggtitle(NULL) + 
  ggplot2::theme(legend.position="bottom") +
  NULL;
```

They are distributed in `r nrow(unique(dplyr::filter(rough_r_data_ie, !is.na(revision) & revision=="trilled" | revision=="other") %>%  dplyr::select(Family)))` language families, with the first 10 largest families being:

```{r}
kable(sort(table(unique(dplyr::select(rough_r_data_ie,Language,Family))$Family), decreasing=TRUE)[1:10], 
      col.names=c("Family", "# languages"), 
      caption=capTab("The largest 10 families in our recoded dataset."));
```

and distributed areally:

```{r}
kable(table(unique(dplyr::select(rough_r_data_ie,Language,Area,Family))$Area), 
      col.names=c("Area", "# languages"), 
      caption=capTab("The areas in our recoded dataset."));
```

The following figure summarizes the changes in language coding following our reanalysis:

```{r fig.width=7, fig.height=8, fig.cap=capFig("Figure showing the effects of our recoding of the languages: the left-most side shows the original coding in Winter et al., in the middle are our recoded values, and, on the gith, the languages included/excluded from our reanalysis.")}
ggplot2::ggplot(data = table_changes_2_ie %>% 
                  mutate("Trill"=factor(ifelse(Trill=="Trill","trilled /r/",Trill), levels=c("trilled /r/", "Other")),
                         "revision"=factor(ifelse(revision=="TRILL","TRILLED /r/", ifelse(revision=="NA","undecid.",as.character(revision))), levels=c("TRILLED /r/", "OTHER", "Contrast", "undecid.", "Error")),
                         "Data"=factor(Data, levels=c("Included", "Excluded"))),
       ggplot2::aes(axis1 = Trill, axis2 = revision, axis3 = Data, y = Freq)) +
  ggalluvial::geom_alluvium(ggplot2::aes(fill = revision)) +
  #ggalluvial::geom_stratum(fill="grey95") +
  #ggalluvial::geom_stratum(aes(fill=revision)) +
  ggalluvial::geom_stratum(fill=c("deepskyblue", "lightyellow", "red", "gray50", "gray70", "deepskyblue", "lightyellow", "white", "darkseagreen1")) +
  ggplot2::geom_text(stat = ggalluvial::StatStratum,
            ggplot2::aes(label = tolower(ggplot2::after_stat(stratum))), color=c("black", "black", NA, "black", "black", "black", "black", "black", "black")) +
  ggplot2::geom_text(stat = ggalluvial::StatAlluvium, position = position_nudge(0.25),
            ggplot2::aes(label = Freq), alpha=0.75, color="grey20") +
  ggplot2::geom_text(stat = ggalluvial::StatAlluvium, position = position_nudge(-0.25),
            ggplot2::aes(label = Freq), alpha=0.75, color="grey20") +
  ggplot2::geom_rect(xmin=-1, xmax=0.83, ymin=-10, ymax=1000, fill="white") + # stupid hack but works
  ggplot2::geom_rect(xmin=3.18, xmax=15, ymin=-10, ymax=1000, fill="white") + 
  ggplot2::scale_x_discrete(limits = c("Survey", "Response"),
                   expand = c(0.15, 0.05)) +
  ggplot2::scale_fill_manual(values=c("OTHER"="blue", "Error"="red", "TRILLED /r/"="yellow", "Contrast"="gray50", "undecid."="black"), 
                             labels=c("OTHER"="other", "Error"="error", "TRILLED /r/"="trilled /r/", "Contrast"="contrast", "undecid."="undecidable"),
                             name="recoding:") +
  ggplot2::theme_void() +
  NULL;

# Save for paper:
ggplot2::ggsave("./figures/Figure1.jpg", device="jpeg", width=6, height=6, units="in", dpi=300, quality=85);
ggplot2::ggsave("./figures/Figure1.tif", device="tiff", width=6, height=6, units="in", dpi=300, compression="lzw", type="cairo", bg="white");
```

We show below a comparison between the distribution of the trilled /r/ in the words 'rough' and 'smooth' in our recoded dataset:

```{r fig.width=2*6, fig.height=4, fig.cap=capFig("The distribution of the trilled /r/ (present, yellow, vs. not, gray) in the words 'rough' (left) and 'smooth' (right) using our recoded dataset, including the IE languages. The languages included differ between the four panel, as explained in the text.")}
base_world +
  ggplot2::geom_sf(size=0.2, col="white", fill="lightgrey") +
  ggplot2::coord_sf(xlim = c(-180, 180), ylim = c(-60, 80), datum=NA) +
  ggplot2::geom_point(data = xling_single_revision_ie, ggplot2::aes(x = Longitude, y = Latitude, fill = r, group = NA),
             alpha = 0.65, size = 2.5,
             col="black", pch=21, stroke=0.75,
             position = ggplot2::position_jitter(width=2.5,height=2.5,seed=1)) +
  ggplot2::facet_grid(~Meaning.f) +
  ggplot2::scale_fill_viridis_d(labels=c("no /r/", "contains /r/")) +
  ggplot2::labs(title = "The recoding") +
  theme_rough +
  ggplot2::theme(
    legend.position = "bottom",
    axis.title = ggplot2::element_blank(),
    axis.text = ggplot2::element_blank(),
    axis.line = ggplot2::element_blank(),
    axis.ticks = ggplot2::element_blank(),
    plot.margin = ggplot2::unit(c(0.1,0.4,-0.4,0.4),"cm"),
    panel.spacing = ggplot2::unit(0, "lines")) + 
  NULL;
```


# Methods

We largely reuse the `R` code made openly available with the original publication [@winter_trilled_2022].

# Results

## Cross-linguistic analysis: replication

Here we do an exact replication (with the addition of formal model comparison and Bayesian hypothesis testing) of the original models in the section "Cross-linguistic analysis" of @winter_trilled_2022.
As per @winter_trilled_2022, we also do not model here *Language* as a random effect, but only *Family* and *Area*.
Likewise, the Indo-European languages are *not* included.

Then, we proceed to various extensions of these models in the following sections.

### Cross-linguistic analysis of languages with trills

```{r}
# Select the recoded languages with trill:
data_R_revision_trill_rs <- dplyr::filter(data_R_revision, revision=="trilled",
                                          Meaning %in% c("rough","smooth"));

data_r_revision_trill_rs_1 <- data_R_revision_trill_rs %>% 
  dplyr::mutate(Trill=ifelse(revision=="trilled","yes"));

# recode as factors:
data_r_revision_trill_rs_1$rough <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_1$rough)+1], levels=c("no", "yes"));
data_r_revision_trill_rs_1$r     <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_1$r)+1],     levels=c("no", "yes"));
data_r_revision_trill_rs_1$l     <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_1$l)+1],     levels=c("no", "yes"));
```

According to our recoding, there are `r length(unique(data_R_revision_trill_rs$Language))` langues with a trill, distributed among `r length(unique(data_R_revision_trill_rs$Family))` language families.

```{r include=FALSE}
file_name <- "./cached/xling_replic_withr.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough +
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_trill_rs_1 ,
              family=binomial()); # singular fit
  rePCA(m1); summary(m1); # seems to be the Area -> let' try to remove (rough | Area)
  m2 <- update(m1, . ~ . - (1 + rough | Area) + (1 | Area)); summary(m2); anova(m1, m2); # all is good (and nova's p=0.94 and ΔAIC=-3.87 in favor of m1)
  m0 <- update(m2, . ~ . - rough); summary(m0); rePCA(m0); # singular fit due to Area but it's the null model so it's probably ok...
  anova(m2, m0); # better than the null (p=0.004, ΔAIC=-6.28)
  plot_prefix <- "./figures/xling_glmer_rs_logistic_mod_r_revision";
  plot_model(m2, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_rs_logistic_mod_r_revision_results <- list("model"=m2, # needed for later comparisons
                                                         "cmp_to_null"=anova(m2, m0), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_trill_rs_1 ,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_trill_rs_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_r_revision";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_trill_rs_1 ,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95 <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_r_revision";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_r_revision_trill_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_trill_rs_1 ,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']"));
  # --> clear positive effect of 'rough'
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_trill_rs_1 ,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # identical
  
  
  xling_brm_rs_logistic_mod_r_revision_results <- list("model"=b1, # needed for later comparisons
                                                       "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix);
  
  # save the results we need later on:
  save(xling_brm_rs_logistic_mod_r_revision_results, 
       xling_glmer_rs_logistic_mod_r_revision_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

For these languages, we fitted a Bayesian logistic regression of *r* (is the trill used?) with *rough* (is the word expressing roughness?) as the only predictor, while including *family* and *macroarea* as random effects (with random intercepts and random slopes for *rough*).

The **prior predictive checks** support the choice of priors are ok:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** show a positive effect of *rough*:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_results$summary,sep="\n"));
```

This is further supported by formal **Bayesian hypothesis testing**:
```{r}
xling_brm_rs_logistic_mod_r_revision_results$hypotheses;
```

and **model comparison** against the null model without *rough*: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_r_revision_results$cmp_to_null)`.

The **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>


Moreover, we also fitted a **frequentist mixed-effects logistic regression** (using `glmer`), but the model with a full random structure was singular; further diagnostics suggested the removal of the random slope of *rough* by *Area*, with which the model converges:
```{r}
summary(xling_glmer_rs_logistic_mod_r_revision_results$model);
```
and shows a positive significant affect of *rough*:
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_glmer_rs_logistic_mod_r_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

and **model comparison** against the null model without *rough* has `r sprintf("*p*=%.3g and ΔAIC=%.1f", xling_glmer_rs_logistic_mod_r_revision_results$cmp_to_null[2,"Pr(>Chisq)"], xling_glmer_rs_logistic_mod_r_revision_results$cmp_to_null$AIC[2] - xling_glmer_rs_logistic_mod_r_revision_results$cmp_to_null$AIC[1])`.

A rough **prior sensitivity analysis** comparing the custom priors with the default (improper) ones used by `brms` results in virtually identical estimates and the formal Bayesian model comparison cannot distinguish between them (details not shown).

Thus, both approaches support a clear positive effect of *rough* on the probability of *r*.



### Cross-linguistic analysis of languages *without* trills

```{r}
# Select the recoded languages without trill:
data_R_revision_other_rs <- dplyr::filter(data_R_revision, revision=="other",
                                          Meaning %in% c("rough","smooth"));

data_r_revision_other_rs_1 <- data_R_revision_other_rs %>% 
  dplyr::mutate(Trill=ifelse(revision=="other","no"));

# recode as factors:
data_r_revision_other_rs_1$rough <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_1$rough)+1], levels=c("no", "yes"));
data_r_revision_other_rs_1$r     <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_1$r)+1],     levels=c("no", "yes"));
data_r_revision_other_rs_1$l     <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_1$l)+1],     levels=c("no", "yes"));
```

According to our recoding, there are `r length(unique(data_R_revision_other_rs$Language))` langues without a trill, distributed among `r length(unique(data_R_revision_other_rs$Family))` language families.

```{r include=FALSE}
file_name <- "./cached/xling_replic_withoutr.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough +
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_other_rs_1 ,
              family=binomial()); # singular fit
  rePCA(m1); summary(m1); # seems to be the Area -> let' try to remove (rough | Area)
  m2 <- update(m1, . ~ . - (1 + rough | Area) + (1 | Area)); summary(m2); anova(m1, m2); # all is good (and nova's p=0.93 and ΔAIC=-3.86 in favor of m1)
  m0 <- update(m2, . ~ . - rough, control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); summary(m0); # using bobyqu to get rid of a "Model failed to converge with max|grad|..." warning
  anova(m2, m0); # better than the null (p=0.017, ΔAIC=-3.75)
  plot_prefix <- "./figures/xling_nt_glmer_rs_logistic_mod_o_revision";
  plot_model(m2, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_rs_logistic_mod_o_revision_results <- list("model"=m2, # needed for later comparisons
                                                         "cmp_to_null"=anova(m2, m0), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_other_rs_1 ,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_other_rs_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_nt_brm_rs_logistic_mod_o_revision";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_other_rs_1 ,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95 <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- "./figures/xling_nt_brm_rs_logistic_mod_o_revision";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_r_revision_other_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_other_rs_1 ,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']"));
  # --> clear positive effect of 'rough'
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_other_rs_1 ,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # identical
  
  
  xling_brm_rs_logistic_mod_o_revision_results <- list("model"=b1, # needed for later comparisons
                                                       "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix);
  
  # save the results we need later on:
  save(xling_brm_rs_logistic_mod_o_revision_results, 
       xling_glmer_rs_logistic_mod_o_revision_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

We fitted a Bayesian logistic regression model as above.

The **prior predictive checks** support the choice of priors are ok:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** show a positive effect of *rough* (but the 95%HDI does include 0)::
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_results$summary,sep="\n"));
```

This is further supported by formal **Bayesian hypothesis testing** for the directional hypothesis, but not if we test against 0:
```{r}
xling_brm_rs_logistic_mod_o_revision_results$hypotheses;
```

and **model comparison** against the null model without *rough* also suggests that adding *rough* is better, but the evidence is much less clear-cut: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_o_revision_results$cmp_to_null)`.

The **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>


Moreover, we also fitted a **frequentist mixed-effects logistic regression** (using `glmer`), but the model with a full random structure was singular; further diagnostics suggested the removal of the random slope of *rough* by *Area*, with which the model converges:
```{r}
summary(xling_glmer_rs_logistic_mod_o_revision_results$model);
```
and shows a positive significant affect of *rough*:
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_glmer_rs_logistic_mod_o_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

and **model comparison** against the null model without *rough* has `r sprintf("*p*=%.3g and ΔAIC=%.1f", xling_glmer_rs_logistic_mod_o_revision_results$cmp_to_null[2,"Pr(>Chisq)"], xling_glmer_rs_logistic_mod_o_revision_results$cmp_to_null$AIC[2] - xling_glmer_rs_logistic_mod_o_revision_results$cmp_to_null$AIC[1])`.

A rough **prior sensitivity analysis** comparing the custom priors with the default (improper) ones used by `brms` results in virtually identical estimates and the formal Bayesian model comparison cannot distinguish between them (details not shown).

Thus, both approaches support a positive effect of *rough* on the probability of *r*, but less clear-cut than above.


### Omnibus analysis: languages with trills & no-trills together

```{r}
# Select the recoded languages:
data_full_revised <- rough_r_data %>%
  dplyr::filter(Family!="Indo-European") %>%
  dplyr::filter(!is.na(revision)) %>% 
  dplyr::mutate(Trill=ifelse(revision=="other","no",
                             ifelse(revision=="trilled","yes",NA))) %>% 
  dplyr::filter(Meaning %in% c("rough","smooth"),
                !is.na(Trill));

# recode as factors:
data_full_revised$rough <- factor(c("no", "yes")[as.numeric(data_full_revised$rough)+1], levels=c("no", "yes"));
data_full_revised$r     <- factor(c("no", "yes")[as.numeric(data_full_revised$r)+1],     levels=c("no", "yes"));
data_full_revised$l     <- factor(c("no", "yes")[as.numeric(data_full_revised$l)+1],     levels=c("no", "yes"));
data_full_revised$Trill <- factor(data_full_revised$Trill,                               levels=c("no", "yes"));
```

According to our recoding, there are `r length(unique(data_full_revised$Language))` langues without a trill, distributed among `r length(unique(data_full_revised$Family))` language families.

```{r include=FALSE}
file_name <- "./cached/xling_replic_omnibus.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough * Trill +
                (1 + rough * Trill | Family) +
                (1 + rough * Trill | Area),
              data=data_full_revised ,
              family=binomial(), 
              control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # singular fit
  rePCA(m1); summary(m1); # seems to be the Area -> let' try to remove (rough | Area)
  m2 <- update(m1, . ~ . - (1 + rough * Trill | Area) + (1 + rough + Trill | Area) -
                 (1 + rough * Trill | Family) + (1 + rough + Trill | Family) - 
                 (1 + rough + Trill | Area) + (1 + rough | Area) - 
                 (1 + rough | Area) + (1 | Area) - 
                 (1 | Area) - 
                 (1 + rough + Trill | Family) + (1 + rough | Family)); rePCA(m2); summary(m2); anova(m1, m2); # ok, not singular...
  m0 <- update(m2, . ~ . - rough * Trill, control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); summary(m0); # using bobyqu to get rid of a "Model failed to converge with max|grad|..." warning
  anova(m2, m0); # better than the null (p=0.0056, ΔAIC=-6.61)
  plot_prefix <- "./figures/xling_glmer_omnibus_mod_r_revision";
  plot_model(m2, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_omnibus_mod_r_revision_results <- list("model"=m2, # needed for later comparisons
                                                     "cmp_to_null"=anova(m2, m0), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough * Trill +
              (1 + rough * Trill | Family) +
              (1 + rough * Trill | Area),
            data=data_full_revised ,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_omnibus_mod_r_revision";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  m_full <- b1;
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/xling_brm_omnibus_mod_r_revision_full";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Family) +
                    (1 | Area),
                  data=data_full_revised ,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  m_full <- brms_fit_indices(m_full);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]")); # full is better than null


  ## following @winter_trilled_2022 observation "When the same model is fitted without by-Family random slopes over Trill, essentially the same results are obtained, but with narrower credible intervals" we also fit a model without these:
  b2_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_original";
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised,
                       prior=b2_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  set.seed(314); # for replicability
  b2 <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised,
                  prior=b2_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_original <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_original <- hdi(b2, ci=0.95));
  m_original <- b2;
  # posterior predictive checks
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_original";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_original <- capture.output(summary(b2));
  probs_text_original <- capture.output(probs_original <- logistic_summary(b2, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_original <- brms_fit_indices(m_original);
  (modcmp_0_original <- brms_compare_models(b0, m_original, "[null]", "[original]")); # original is better than null
  (modcmp_full_original <- brms_compare_models(m_full, m_original, "[full]", "[original]")); # original is better than full
  # ---> indeed, m_original seems slightly better, so we'll use it here (just as @winter_trilled_2022 suggest)

  
  ## check if Trill:rough really matters (because it seems it might not):
  b3_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area")
  ); # for the full model
  set.seed(314); # for replicability
  b3 <- brms::brm(r ~ 1 + rough + Trill +
                         (1 + rough | Family) +
                         (1 + rough + Trill | Area),
                       data=data_full_revised,
                  prior=b3_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_noint <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0")));
  (hdi95_noint <- hdi(b3, ci=0.95));
  m_noint <- b3;
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/xling_brm_omnibus_mod_r_revision_noint";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b3));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b3, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_noint <- brms_fit_indices(m_noint);
  (modcmp_0_noint <- brms_compare_models(b0, m_noint, "[null]", "[noint]")); # noint is better than null
  (modcmp_full_noint <- brms_compare_models(m_full, m_noint, "[full]", "[noint]")); # noint is better than full
  (modcmp_original_noint <- brms_compare_models(m_original, m_noint, "[original]", "[noint]")); # they are relatively equivalent but with a hint that noint is better
  # -> we can remove the interaction Trill:rough...


  # check if Trill is needed at all (because it seems it might not):
  b4_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # no Trill
  set.seed(314); # for replicability
  b4 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_full_revised,
                  prior=b4_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b4); mcmc_plot(b4, type="trace"); mcmc_plot(b4);
  (hyps_notrill <- brms::hypothesis(b4, c("roughyes = 0", "roughyes > 0")));
  (hdi95_notrill <- hdi(b4, ci=0.95));
  m_notrill <- b4;
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/xling_brm_omnibus_mod_r_revision_notrill";
  mcmc_plot(b4, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b4); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b4, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b4));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b4, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b4, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b4, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b4, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b4, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_notrill <- brms_fit_indices(m_notrill);
  (modcmp_0_notrill <- brms_compare_models(b0, m_notrill, "[null]", "[notrill]")); # notrill is better than null
  (modcmp_full_notrill <- brms_compare_models(m_full, m_notrill, "[full]", "[notrill]")); # notrill is better than full
  (modcmp_original_notrill <- brms_compare_models(m_original, m_notrill, "[original]", "[notrill]")); # they are relatively equivalent but with a hint that notrill is better
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]")); # they are equivalent
  # -> so, Trill is not needed at all...
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b2f <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2f); mcmc_plot(b2f, type="trace"); mcmc_plot(b2f);
  (hyps_f <- brms::hypothesis(b2f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b2f, ci=0.95));
  pp_check(b2f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b2f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b2f <- brms_fit_indices(b2f);
  (modcmp_f <- brms_compare_models(m_original, b2f, "[custom prior]", "[default prior]")); # virtually identical

  
  xling_brm_omnibus_mod_r_revision_results <- list("full"=list("model"=m_full, # needed for later comparisons
                                                               "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                                               "cmp_to_null"=modcmp_0_full, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                                                   "original"=list("model"=m_original, # needed for later comparisons
                                                               "summary"=summary_mod_original, "hypotheses"=hyps_original, "hdi95"=hdi95_original, 
                                                               "cmp_to_null"=modcmp_0_original,  "cmp_to_full"=modcmp_full_original, "probs"=probs_original, "probs_text"=probs_text_original, "plot_prefix"=plot_prefix_original),
                                                   "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                                               "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                                               "cmp_to_null"=modcmp_0_noint,  "cmp_to_full"=modcmp_full_noint, "cmp_to_original"=modcmp_original_noint, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                                                   "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                                               "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                                               "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_original"=modcmp_original_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                                               "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill));
  
  # save the results we need later on:
  save(xling_brm_omnibus_mod_r_revision_results, 
       xling_glmer_omnibus_mod_r_revision_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

As per @winter_trilled_2022, we chose as our model the one where there is no random slope for *Trill* by *Family* (aka 'original'), as it seems to be rather equivalent to the 'full' model (if not slightly better): 
`r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$original$cmp_to_full)`

and the estimates of the effects are quite similar:
<center>![The estimates of the effects in the 'full' model.](`r paste0(xling_brm_omnibus_mod_r_revision_results$full$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

<center>![The estimates of the effects in the 'original' (as per @winter_trilled_2022) model, excluding the random random slope for *Trill* by *Family*.](`r paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

The **prior predictive checks** support the choice of priors are ok:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the results show a positive effect of *rough* but not of *Trill*, nor of their interaction (see also the estimates plot above):
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_results$original$summary,sep="\n"));
```

This is further supported by formal **Bayesian hypothesis testing**:
```{r}
xling_brm_omnibus_mod_r_revision_results$original$hypotheses;
```

**Model comparison** against the null model clearly shows that it is better than the null (due to *rough*, model comparison not shown here):  `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$original$cmp_to_null)`.

The **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_results$original$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_pred.jpg")`){width="4in"}</center>


Moreover, we also fitted a **frequentist mixed-effects logistic regression** (using `glmer`), but the model with a full random structure was singular; further diagnoses and model fitting resulted in a much simpler random structure with only a  random intercept and random slope for *rough* by *Family* and no random structure for *Area*, with which the model converges:
```{r}
summary(xling_glmer_omnibus_mod_r_revision_results$model);
```
and shows a positive significant affect of *rough*:
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_glmer_omnibus_mod_r_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

and **model comparison** against the null model without *rough* has `r sprintf("*p*=%.3g and ΔAIC=%.1f", xling_glmer_omnibus_mod_r_revision_results$cmp_to_null[2,"Pr(>Chisq)"], xling_glmer_omnibus_mod_r_revision_results$cmp_to_null$AIC[2] - xling_glmer_omnibus_mod_r_revision_results$cmp_to_null$AIC[1])`.

A rough **prior sensitivity analysis** comparing the custom priors with the default (improper) ones used by `brms` results in virtually identical estimates and the formal Bayesian model comparison cannot distinguish between them (details not shown).


### @winter_trilled_2022 vs revised models side-by-side

The predictions of the @winter_trilled_2022 models are:

```{r include=FALSE}
# load the original model results:
xling_brm_rs_logistic_mod_r <- readRDS("models/xling_brm_rs_logistic_mod_r.rds");
xling_nt_brm_rs_logistic_mod_r <- readRDS("models/xling_nt_brm_rs_logistic_mod_r.rds");
```

- for languages **with** a trill:

```{r}
mod_preds_trill <- logistic_summary(xling_brm_rs_logistic_mod_r, dat=xling, outcome="/r/", roughpred="rough", pp_over_zero=TRUE);
mod_dat_trill <- data.frame(Meaning.f=factor(c("‘smooth’", "‘rough’"), levels=c("‘smooth’", "‘rough’")),
                            pred=c(mean(mod_preds_trill$pred_prob_smooth),mean(mod_preds_trill$pred_prob_rough))*100,
                            ll=c(quantile(mod_preds_trill$pred_prob_smooth, 0.025),quantile(mod_preds_trill$pred_prob_rough, 0.025))*100,
                            ul=c(quantile(mod_preds_trill$pred_prob_smooth, 0.975),quantile(mod_preds_trill$pred_prob_rough, 0.975))*100);
```

- for languages **without** a trill:

```{r}
mod_preds_nt <- logistic_summary(xling_nt_brm_rs_logistic_mod_r, dat=xling, outcome="/r/", roughpred="rough", pp_over_zero=TRUE);
mod_dat_nt <- data.frame(Meaning.f=factor(c("‘smooth’", "‘rough’"), levels=c("‘smooth’", "‘rough’")),
                         pred=c(mean(mod_preds_nt$pred_prob_smooth),mean(mod_preds_nt$pred_prob_rough))*100,
                         ll=c(quantile(mod_preds_nt$pred_prob_smooth, 0.025),quantile(mod_preds_nt$pred_prob_rough, 0.025))*100,
                         ul=c(quantile(mod_preds_nt$pred_prob_smooth, 0.975),quantile(mod_preds_nt$pred_prob_rough, 0.975))*100);
```

```{r include=FALSE}
mod_dat <- bind_rows(mod_dat_trill, mod_dat_nt) %>%
  dplyr::mutate(Trill=factor(c("trilled /r/","trilled /r/","other /r/","other /r/"), levels=c("trilled /r/","other /r/")));

r_per_family <- xling %>%
  dplyr::group_by(Family, Trill, Meaning.f) %>%
  dplyr::summarise(perc_r = mean(r)*100, n=length(unique(Language))) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Trill=recode(Trill, yes="trilled /r/", no="other /r/"), Trill=factor(Trill, levels=c("trilled /r/","other /r/")));
```

While the predictions using our recoding are:

- for languages **with** a trill:

```{r}
mod_preds_trill_revision <- xling_brm_rs_logistic_mod_r_revision_results$probs;
mod_dat_trill_revision <- data.frame(Meaning.f=factor(c("‘smooth’", "‘rough’"), levels=c("‘smooth’", "‘rough’")),
                                     pred=c(mean(mod_preds_trill_revision$pred_prob_smooth),mean(mod_preds_trill_revision$pred_prob_rough))*100,
                                     ll=c(quantile(mod_preds_trill_revision$pred_prob_smooth, 0.025),quantile(mod_preds_trill_revision$pred_prob_rough, 0.025))*100,
                                     ul=c(quantile(mod_preds_trill_revision$pred_prob_smooth, 0.975),quantile(mod_preds_trill_revision$pred_prob_rough, 0.975))*100);
cat(paste0(xling_brm_rs_logistic_mod_r_revision_results$probs_text, sep="\n"));
```

- for languages **without** a trill:

```{r}
mod_preds_nt_revision <- xling_brm_rs_logistic_mod_o_revision_results$probs;
mod_dat_nt_revision <- data.frame(Meaning.f=factor(c("‘smooth’", "‘rough’"), levels=c("‘smooth’", "‘rough’")),
                                  pred=c(mean(mod_preds_nt_revision$pred_prob_smooth),mean(mod_preds_nt_revision$pred_prob_rough))*100,
                                  ll=c(quantile(mod_preds_nt_revision$pred_prob_smooth, 0.025),quantile(mod_preds_nt_revision$pred_prob_rough, 0.025))*100,
                                  ul=c(quantile(mod_preds_nt_revision$pred_prob_smooth, 0.975),quantile(mod_preds_nt_revision$pred_prob_rough, 0.975))*100);
cat(paste0(xling_brm_rs_logistic_mod_o_revision_results$probs_text, sep="\n"));
```

```{r include=FALSE}
mod_dat_revision <- bind_rows(mod_dat_trill_revision, mod_dat_nt_revision) %>%
  dplyr::mutate(Trill=factor(c("trilled /r/","trilled /r/","other /r/","other /r/"), levels=c("trilled /r/","other /r/")));

# raw figures / language family
r_per_family_revision <- xling_revision %>%
  dplyr::group_by(Family, Trill, Meaning.f) %>%
  dplyr::summarise(perc_r = mean(r)*100, n=length(unique(Language))) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Trill=recode(Trill, yes="trilled /r/", no="other /r/"), Trill=factor(Trill, levels=c("trilled /r/","other /r/")));

```

And visually:

```{r fig.width=9, fig.height=3.5*2, fig.cap=capFig("Model predictions: the original study of Winter et al. (top) and using the present recoding (bottom). For both plots: left: languages with trilled /r/ in their phonemic inventory; left : languages with a different (non-trilled) kind of /r/. The results are aggregated per family, each colored circle represening one family and the size of the circles is proportional to the number of languages in the family. The big gray circles are the model predicitons with their 95% HDIs.")}
grid.arrange(ggplot2::ggplot(data = r_per_family, ggplot2::aes(x = Meaning.f, y = perc_r)) + # @winter_trilled_2022
               ggplot2::facet_grid(. ~ Trill) +
               ggplot2::geom_point(data=r_per_family, 
                                   ggplot2::aes(color = perc_r, size = n), alpha = 0.5,
                                   position = ggbeeswarm::position_quasirandom(width = 0.3)) +
               ggplot2::geom_errorbar(data=mod_dat,
                                      ggplot2::aes(ymin = ll, ymax = ul, y=NULL), 
                                      width = 0.075) +
               ggplot2::geom_point(data=mod_dat, 
                                   ggplot2::aes(y=pred), fill="grey", 
                                   size = 6, shape = 21) +
               ggplot2::scale_color_gradient(guide = F,
                                             low=other_col, high=r_col) +
               ggplot2::scale_y_continuous(breaks=seq(0,100,25), labels=paste0(seq(0,100,25), "%")) +
               ggplot2::scale_size_continuous(guide = FALSE, range = c(2,6)) +
               ggplot2::labs(title = "The original study",
                             y = "% forms with /r/", 
                             x = "\n") +
               theme_rough +
               ggplot2::theme(plot.margin = unit(c(0.4,0.4,-0.6,0.4),"cm")) + 
               NULL,
             
             ggplot2::ggplot(data = r_per_family_revision, aes(x = Meaning.f, y = perc_r)) + # revised
               ggplot2::facet_grid(. ~ Trill) +
               ggplot2::geom_point(data=r_per_family_revision, 
                                   ggplot2::aes(color = perc_r, size = n), alpha = 0.5,
                                   position = ggbeeswarm::position_quasirandom(width = 0.3)) +
               ggplot2::geom_errorbar(data=mod_dat_revision,
                                      ggplot2::aes(ymin = ll, ymax = ul, y=NULL), 
                                      width = 0.075) +
               ggplot2::geom_point(data=mod_dat_revision, 
                                   ggplot2::aes(y=pred), fill="grey", 
                                   size = 6, shape = 21) +
               ggplot2::scale_color_gradient(guide = F,
                                             low=other_col, high=r_col) +
               ggplot2::scale_y_continuous(breaks=seq(0,100,25), labels=paste0(seq(0,100,25), "%")) +
               ggplot2::scale_size_continuous(guide = FALSE, range = c(2,6)) +
               ggplot2::labs(title = "Using the recoding",
                             y = "% forms with /r/", 
                             x = "\n") +
               theme_rough +
               ggplot2::theme(plot.margin = unit(c(0.4,0.4,-0.6,0.4),"cm")) + 
               NULL,
             ncol=1);
```

```{r include=FALSE}
# Let's compare the posterior differences of the models:
posterior_all <- rbind(data.frame("estimate"=mod_preds_trill$pred_prob_smooth,          "study"="original", "trill"="trill", "concept"="smooth"),
                       data.frame("estimate"=mod_preds_trill$pred_prob_rough,           "study"="original", "trill"="trill", "concept"="rough"),
                       data.frame("estimate"=mod_preds_nt$pred_prob_smooth,             "study"="original", "trill"="no trill",  "concept"="smooth"),
                       data.frame("estimate"=mod_preds_nt$pred_prob_rough,              "study"="original", "trill"="no trill",  "concept"="rough"),
                       data.frame("estimate"=mod_preds_trill_revision$pred_prob_smooth, "study"="recoding", "trill"="trill", "concept"="smooth"),
                       data.frame("estimate"=mod_preds_trill_revision$pred_prob_rough,  "study"="recoding", "trill"="trill", "concept"="rough"),
                       data.frame("estimate"=mod_preds_nt_revision$pred_prob_smooth,    "study"="recoding", "trill"="no trill",  "concept"="smooth"),
                       data.frame("estimate"=mod_preds_nt_revision$pred_prob_rough,     "study"="recoding", "trill"="no trill",  "concept"="rough"));
posterior_all$study   <- factor(posterior_all$study,   levels=c("original", "recoding"));
posterior_all$trill   <- factor(posterior_all$trill,   levels=c("no trill", "trill"));
posterior_all$concept <- factor(posterior_all$concept, levels=c("rough", "smooth"));

posterior_diff <- rbind(data.frame("diff"=mod_preds_trill$pred_prob_diff,          "study"="original", "trill"="trill"),
                        data.frame("diff"=mod_preds_nt$pred_prob_diff,             "study"="original", "trill"="no trill"),
                        data.frame("diff"=mod_preds_trill_revision$pred_prob_diff, "study"="recoding", "trill"="trill"),
                        data.frame("diff"=mod_preds_nt_revision$pred_prob_diff,    "study"="recoding", "trill"="no trill"));
posterior_diff$study <- factor(posterior_diff$study,   levels=c("original", "recoding"));
posterior_diff$trill <- factor(posterior_diff$trill,   levels=c("no trill", "trill"));

# statistical tests:
(t_nt_rough  <- t.test(estimate ~ study, data=posterior_all[ posterior_all$trill == "no trill" & posterior_all$concept == "rough", ], paired=FALSE));
(t_nt_smooth <- t.test(estimate ~ study, data=posterior_all[ posterior_all$trill == "no trill" & posterior_all$concept == "smooth", ], paired=FALSE));
(t_tr_rough  <- t.test(estimate ~ study, data=posterior_all[ posterior_all$trill == "trill" & posterior_all$concept == "rough", ], paired=FALSE));
(t_tr_smooth <- t.test(estimate ~ study, data=posterior_all[ posterior_all$trill == "trill" & posterior_all$concept == "smooth", ], paired=FALSE));

(t_diff_nt  <- t.test(diff ~ study, data=posterior_diff[ posterior_diff$trill == "no trill", ], paired=FALSE));
(t_diff_tr  <- t.test(diff ~ study, data=posterior_diff[ posterior_diff$trill == "trill", ], paired=FALSE));
```

```{r fig.width=2*3, 2*3, fig.cap=capFig("Posterior distribution of the estimated probability of /r/ comparing the original [Winter et al.] study (gray) and the recoded study (yellow) separately for the two concepts ('smooth' and 'rough') and the languages with and without a trilled /r/. All independent two sample *t*-tests are highly significant (an artefact of the large posterior sample size), but the actual mean differences between this confirms visually that for the languages without a trill the two studies differ quite dramatically (more /r/ for 'rough' with the recoding but less for 'smooth').")}
ggplot(posterior_all, aes(x=estimate, fill=study)) + 
  geom_density(color="black", alpha=0.25) + 
  facet_grid(trill ~ concept) +
  xlab("Probability of /r/") +
  scale_fill_viridis_d() +
  NULL;
```

```{r fig.width=2*3, fig.height=3, fig.cap=capFig("Distribution of the posterior differences in the probability of /r/ between the two concepts ('rough' - 'smooth') separately for the languages with and without a trilled /r/. Same conventions as above.")}
ggplot(posterior_diff, aes(x=diff, fill=study)) + 
  geom_density(color="black", alpha=0.25) + 
  facet_wrap(trill ~ .) +
  xlab("Δ probability of /r/ ('rough' - 'smooth')") +
  scale_fill_viridis_d() +
  NULL;
```


```{r include=FALSE}
# Plot for paper:

jpeg("./figures/Figure2.jpg",  width=5, height=7, units="in", quality=85, res=300);
grid.arrange(ggplot2::ggplot(data = r_per_family, ggplot2::aes(x = Meaning.f, y = perc_r)) + # @winter_trilled_2022
               ggplot2::facet_grid(. ~ Trill) +
               ggplot2::geom_point(data=r_per_family, 
                                   ggplot2::aes(color = perc_r, size = n), alpha = 0.5,
                                   position = ggbeeswarm::position_quasirandom(width = 0.3)) +
               ggplot2::geom_errorbar(data=mod_dat,
                                      ggplot2::aes(ymin = ll, ymax = ul, y=NULL), 
                                      width = 0.075) +
               ggplot2::geom_point(data=mod_dat, 
                                   ggplot2::aes(y=pred), fill="grey", 
                                   size = 6, shape = 21) +
               ggplot2::scale_color_gradient(guide = F,
                                             low=other_col, high=r_col) +
               ggplot2::scale_y_continuous(breaks=seq(0,100,25), labels=paste0(seq(0,100,25), "%")) +
               ggplot2::scale_size_continuous(guide = FALSE, range = c(2,6)) +
               ggplot2::labs(title = "The original study",
                             y = "% forms with /r/", 
                             x = "\n") +
               theme_rough +
               ggplot2::theme(plot.margin = unit(c(0.4,0.4,-0.6,0.4),"cm"), plot.title = element_text(hjust = 0.5)) + 
               NULL,
             
             ggplot2::ggplot(data = r_per_family_revision, aes(x = Meaning.f, y = perc_r)) + # revised
               ggplot2::facet_grid(. ~ Trill) +
               ggplot2::geom_point(data=r_per_family_revision, 
                                   ggplot2::aes(color = perc_r, size = n), alpha = 0.5,
                                   position = ggbeeswarm::position_quasirandom(width = 0.3)) +
               ggplot2::geom_errorbar(data=mod_dat_revision,
                                      ggplot2::aes(ymin = ll, ymax = ul, y=NULL), 
                                      width = 0.075) +
               ggplot2::geom_point(data=mod_dat_revision, 
                                   ggplot2::aes(y=pred), fill="grey", 
                                   size = 6, shape = 21) +
               ggplot2::scale_color_gradient(guide = F,
                                             low=other_col, high=r_col) +
               ggplot2::scale_y_continuous(breaks=seq(0,100,25), labels=paste0(seq(0,100,25), "%")) +
               ggplot2::scale_size_continuous(guide = FALSE, range = c(2,6)) +
               ggplot2::labs(title = "Using the recoding",
                             y = "% forms with /r/", 
                             x = "\n") +
               theme_rough +
               ggplot2::theme(plot.margin = unit(c(0.4,0.4,-0.6,0.4),"cm"), plot.title = element_text(hjust = 0.5)) + 
               NULL,
             
             ggplot(posterior_diff %>%
                      mutate(trill = factor(ifelse(trill=="trill", "trilled /r/", "other"), levels=c("trilled /r/", "other"))),
                    aes(x=diff, fill=study)) + 
               geom_density(color="black", alpha=0.25) + 
               geom_vline(xintercept=c(-0.25, 0.00, 0.25, 0.50), color="gray50", linetype=c("dashed", "solid", "dashed", "dashed", "dashed", "solid", "dashed", "dashed"), size=0.25) +
               facet_wrap(trill ~ .) +
               ggplot2::labs(title = 'p(/r/ | "rough") - p(/r/ | "smooth")',
                             y = "density\n\n", 
                             x = "") +
               #xlab("Δ probability of /r/ ('rough' - 'smooth')") +
               scale_fill_manual(values=c("original"="blue", "recoding"="yellow")) + theme_rough + 
               theme(legend.position="none", 
                     plot.title = element_text(hjust = 0.5)) + 
               NULL,
             
             ncol=1);
dev.off();

#ggplot2::ggsave("./figures/Figure2.tif", device="tiff", width=9, height=7, units="in", dpi=300, compression="lzw", type="cairo", bg="white");
```



## Cross-linguistic analysis: in depth

Here we look a bit more in depth at this cross-linguistic analysis, in particular at:

- does *Trill* really matter?
- including *Language* as a random effect, and
- including the Indo-European (IE) languages as well.



### Does *Trill* really matter in the omnibus model?

When looking in detail at the omnibus model discussed above, it seems that *Trill* does not make any contribution whatsoever; as a reminder, the "original" model is the one used by @winter_trilled_2022 (which includes the interaction between *rough* and *Trill* as a fixed effect, and random slopes for this for *Area* but not for *Family*), while the "best" model is one without *Trill* (and its interaction with *rough*): `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$best$cmp_to_original)`

and the effects involving Trill in the original model do not seem to matter in terms of formal **Bayesian hypothesis testing** too:
```{r}
xling_brm_omnibus_mod_r_revision_results$original$hypotheses;
```

Removing the interaction *rough*:*Trill* results in a similar (or arguably, even a slightly better) fit: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$noint$cmp_to_original)`.

However the **Bayesian hypothesis testing** still suggests that *Trill* does not even have a main effect:
```{r}
xling_brm_omnibus_mod_r_revision_results$noint$hypotheses;
```

which is supported by **model comparison**: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$notrill$cmp_to_noint)`.

This model without *Trill* converges well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_results$notrill$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and show a positive effect of *rough*:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_omnibus_mod_r_revision_results$notrill$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_results$notrill$summary,sep="\n"));
```

This is further supported by formal **Bayesian hypothesis testing**:
```{r}
xling_brm_omnibus_mod_r_revision_results$notrill$hypotheses;
```

and **model comparison** against the null model clearly shows that it is better than the null: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_results$notrill$cmp_to_null)`.

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_results$notrill$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_results$notrill$plot_prefix,"_pred.jpg")`){width="4in"}</center>

Thus, it seems that *Trill* has no effect on *r*, but *rough* does.


### Random effect for *Language*

@winter_trilled_2022 justify not including *Language* as a random effect by saying (in the `HTML` report of the analysis, section 4.1 "Cross-linguistic analysis of languages with trills") that "[w]e include random effects by Family/Area (not by language, as most languages only have one rough and one smooth word)".
While it is technically true that the number of observations (i.e., included words) per language is hugely skewed towards small numbers:

```{r fig.width=5, fig.height=5, fig.cap=capFig("Histogram of the number of observations (i.e., words) per language in the revised omnibus dataset, also showing the percent of languages with a given number of observations.")}
x <- as.numeric(table(data_full_revised$Language));
h <- hist(x, plot=FALSE, breaks=max(x)-min(x)+1);
hist(x, labels=ifelse(h$counts > 0, as.character(round(h$counts / length(x) * 100, 1)), ""), main=NULL, breaks=max(x)-min(x)+1, xaxt = "n", ylim=c(0,max(h$counts)+50), xlab="# of words per language");
axis(1, min(x):(max(x)-1)+0.5, labels = min(x):(max(x)-1), tick = FALSE, las=3);
```

with `r sum(table(data_full_revised$Language) > 1)` languages having more than 1 such word and only `r sum(table(data_full_revised$Language) > 2)` with more than 2.
Nevertheless, the inclusion of *Language* as a random effect *is* justified theoretically arguably even more than of *Family* and *Area*, as it is to be expected that language-specific factors related to phonetics/phonology, semantics, etc. are expected to play a major role in creating correlations between a word's languages, including for 'smooth' and 'rough', and Bayesian models are more than capable of correctly dealing with the "degenerated" cases of languages with only 1 word.
However, one potential issue is that by introducing this random effects structure we may explode the number of parameters to estimate beyond the information that the data actually contain.
Nevertheless, we also include *Language* as a random factor here and we also test the models with and without it.

#### Languages with trills

```{r include=FALSE}
file_name <- "./cached/xling_replic_withr_langrand.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough +
                (1 + rough | Language) + # language is nested within families so no need to include their interaction
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_trill_rs_1,
              family=binomial()); 
  # Error: number of observations (=247) < number of random effects (=248) for term (1 + rough | Language); the random-effects parameters are probably unidentifiable
  # so, we can't model this meaningfully in a frequentist way (and it also suggests that for the Bayesian approach, the prior might have too much influence)
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Language) + # language is nested within families so no need to include their interaction
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_trill_rs_1,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Language) + # language is nested within families so no need to include their interaction
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_trill_rs_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_r_revision_langrand";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) + # language is nested within families so no need to include their interaction
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_trill_rs_1,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95 <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_r_revision_langrand";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_r_revision_trill_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_trill_rs_1,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']"));
  # --> clear positive effect of 'rough'
  
  (modcmp2 <- brms_compare_models(xling_brm_rs_logistic_mod_r_revision_results$model, b1, "[original]", "[with Language]")); # slight advantage for including Language
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) + # language is nested within families so no need to include their interaction
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_trill_rs_1,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # there seems to be a slight advantage to the default prior and the estimates are slightly different (smaller for the custom prior)
  mcmc_plot(b1f); ggsave(paste0(plot_prefix,"_default_priors_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1f, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_default_priors_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);

  
  xling_brm_rs_logistic_mod_r_revision_langrand_results <- list("model"=NULL, #xling_brm_rs_logistic_mod_r_revision, # needed for later comparisons
                                                                "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, "cmp_to_original"=modcmp2, 
                                                                "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix,
                                                                "default_priors_summary"=capture.output(summary(b1f)), 
                                                                "default_priors_probs_text"=capture.output(probs <- logistic_summary(b1f, dat=data_r_revision_trill_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE)),
                                                                "cmp_to_default_priors"=modcmp_f);
  save(xling_brm_rs_logistic_mod_r_revision_langrand_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

We tried to fit a frequentist model as well (using `glmer`) but this failed with the error "number of observations (=247) < number of random effects (=248) for term (1 + rough | Language); the random-effects parameters are probably unidentifiable", which suggests that, indeed, even in the Bayesian models there might not be enough data to fully inform this random effects structure.

With this caveat in mind, our Bayesian model does **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** show a positive effect of *rough*:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$summary,sep="\n"));
```

This is further supported by formal **Bayesian hypothesis testing**:
```{r}
xling_brm_rs_logistic_mod_r_revision_langrand_results$hypotheses;
```

and **model comparison** against the null model without *rough*: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_r_revision_langrand_results$cmp_to_null)`.

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and the **posterior predictive checks** also seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

However, the priors do seem to influence the posterior estimates (as expected, given the suggestion discussed above that this full random structure may exceed the information provided by the data), but only in terms of the position of the posterior distribution:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals using the default ("uninformative") priors.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_default_priors_mcmcestim.jpg")`){width="4in"}</center>
<center>![The effect of the predictors on the probability of *r* using the default ("uninformative") priors.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_default_priors_pred.jpg")`){width="4in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$default_priors_probs_text,sep="\n"));
```
and formal model comparison between these two priors suggests that they are essentially equivalent but with a slight advantage for the default prior.

As a reminder, these are the equivalent results for the original model without *Language* as a random effect:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_r_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

Finally, this model is slightly better than the original one without *Language* as a random effect: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_r_revision_langrand_results$cmp_to_original)`.

Thus, including *Language* as a random effect seems warranted both theoretically and in terms of improved fit, and their results are very similar.


#### Languages *without* trills

```{r include=FALSE}
file_name <- "./cached/xling_replic_withoutr_langrand.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough +
                (1 + rough | Language) + # language is nested within families so no need to include their interaction
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_other_rs_1,
              family=binomial()); 
  # Error: number of observations (=254) < number of random effects (=264) for term (1 + rough | Language); the random-effects parameters are probably unidentifiable
  # so, we can't model this meaningfully in a frequentist way (and it also suggests that for the Bayesian approach, the prior might have too much influence)
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Language) + # language is nested within families so no need to include their interaction
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_other_rs_1,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Language) + # language is nested within families so no need to include their interaction
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_other_rs_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_o_revision_langrand_results";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) + # language is nested within families so no need to include their interaction
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_other_rs_1,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95 <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_o_revision_langrand_results";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_r_revision_other_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_other_rs_1,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']"));
  # --> positive effect of 'rough' (but less strong than for the languages with "r")

  (modcmp2 <- brms_compare_models(xling_brm_rs_logistic_mod_o_revision_results$model, b1, "[original]", "[with Language]")); # quite similar
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) + # language is nested within families so no need to include their interaction
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_other_rs_1,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # they seem equivalent
  mcmc_plot(b1f); ggsave(paste0(plot_prefix,"_default_priors_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1f, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_default_priors_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);

  
  xling_brm_rs_logistic_mod_o_revision_langrand_results <- list("model"=NULL, #xling_brm_rs_logistic_mod_r_revision, # needed for later comparisons
                                                                "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, "cmp_to_original"=modcmp2, 
                                                                "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix,
                                                                "default_priors_summary"=capture.output(summary(b1f)), 
                                                                "default_priors_probs_text"=capture.output(probs <- logistic_summary(b1f, dat=data_r_revision_trill_rs_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE)),
                                                                "cmp_to_default_priors"=modcmp_f);
  save(xling_brm_rs_logistic_mod_o_revision_langrand_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

As above, we tried to fit a frequentist model as well (using `glmer`) but this failed with the error "number of observations (=254) < number of random effects (=264) for term (1 + rough | Language); the random-effects parameters are probably unidentifiable", which suggests that, indeed, even in the Bayesian models there might not be enough data to fully inform this random effects structure.

The model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** suggest a positive effect of *rough* (but the 95%HDI does include 0):
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$summary,sep="\n"));
```

Likewise, formal **Bayesian hypothesis testing** fail to find an effect of *rough*:
```{r}
xling_brm_rs_logistic_mod_o_revision_langrand_results$hypotheses;
```

but **model comparison** against the null model without *rough* does suggests that adding *rough* might make a difference: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_o_revision_langrand_results$cmp_to_null)`.

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and the **posterior predictive checks** also seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_langrand_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

Here, the priors seem to have an even stronger influence on the posterior estimates:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals using the default ("uninformative") priors.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_default_priors_mcmcestim.jpg")`){width="4in"}</center>
<center>![The effect of the predictors on the probability of *r* using the default ("uninformative") priors.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$plot_prefix,"_default_priors_pred.jpg")`){width="4in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_results$default_priors_probs_text,sep="\n"));
```
but formal model comparison between these two priors suggests that they are essentially equivalent.

As a reminder, these are the equivalent results for the original model without *Language* as a random effect:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_o_revision_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

Finally, this model is marginally better (or equivalent to) than the original one without *Language* as a random effect: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_o_revision_langrand_results$cmp_to_original)`.

Thus, including *Language* as a random effect seems warranted, and their results are very similar, except that the effect of *rough* is now formally not significant anymore.


#### Omnibus analysis

```{r include=FALSE}
file_name <- "./cached/xling_replic_omnibus_langrand.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough * Trill +
                (1 + rough * Trill | Language) +
                (1 + rough * Trill | Family) +
                (1 + rough * Trill | Area),
              data=data_full_revised,
              family=binomial()); 
  # Error: number of observations (=501) < number of random effects (=1024) for term (1 + rough * Trill | Language); the random-effects parameters are probably unidentifiable
  # so, we can't model this meaningfully in a frequentist way (and it also suggests that for the Bayesian approach, the prior might have too much influence)
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough * Trill +
              (1 + rough * Trill | Language) +
              (1 + rough * Trill | Family) +
              (1 + rough * Trill | Area),
            data=data_full_revised,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough * Trill | Language) +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_full";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough * Trill | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_full";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b1 <- brms_fit_indices(b1);
  m_full <- b1;
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_full_revised,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]")); # full is better than null


  # following @winter_trilled_2022 observation "When the same model is fitted without by-Family random slopes over Trill, essentially the same results are obtained, but with narrower credible intervals" we also fit a model without these:
  b2_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # no random slppes for Trill by Family
  # prior predictive checks:
  set.seed(314); # for replicability
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_original";
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough | Language) +
                         (1 + rough | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised,
                       prior=b2_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  set.seed(314); # for replicability
  b2 <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised,
                  prior=b2_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_original <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_original <- hdi(b2, ci=0.95));
  m_original <- b2;
  # posterior predictive checks
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_original";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_original <- capture.output(summary(b2));
  probs_text_original <- capture.output(probs_original <- logistic_summary(b2, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_original <- brms_fit_indices(m_original);
  (modcmp_0_original <- brms_compare_models(b0, m_original, "[null]", "[original]")); # original is better than null
  (modcmp_full_original <- brms_compare_models(m_full, m_original, "[full]", "[original]")); # they seem at least identical, with a hint of full being better
  # -> no reason to pick the original over the full here...
  
  
  ## check if Trill:rough really matters (because it seems it might not):
  b3_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area")
  ); # no interaction
  set.seed(314); # for replicability
  b3 <- brms::brm(r ~ 1 + rough + Trill +
                    (1 + rough + Trill | Language) +
                    (1 + rough + Trill | Family) +
                    (1 + rough + Trill | Area),
                  data=data_full_revised,
                  prior=b3_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_noint <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0")));
  (hdi95_noint <- hdi(b3, ci=0.95));
  m_noint <- b3;
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_noint";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b3));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b3, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_noint <- brms_fit_indices(m_noint);
  (modcmp_0_noint <- brms_compare_models(b0, m_noint, "[null]", "[noint]")); # noint is better than null
  (modcmp_full_noint <- brms_compare_models(m_full, m_noint, "[full]", "[noint]")); # they seem largely equivalent with a hint that full is better
  (modcmp_original_noint <- brms_compare_models(m_original, m_noint, "[original]", "[noint]")); # they are equivalent
  # -> we can remove the interaction Trill:rough...


  # check if Trill is needed at all (because it seems it might not):
  b4_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # no Trill
  set.seed(314); # for replicability
  b4 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_full_revised,
                  prior=b4_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b4); mcmc_plot(b4, type="trace"); mcmc_plot(b4);
  (hyps_notrill <- brms::hypothesis(b4, c("roughyes = 0", "roughyes > 0")));
  (hdi95_notrill <- hdi(b4, ci=0.95));
  m_notrill <- b4;
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_notrill";
  mcmc_plot(b4, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b4); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b4, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b4));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b4, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b4, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b4, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b4, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b4, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_notrill <- brms_fit_indices(m_notrill);
  (modcmp_0_notrill <- brms_compare_models(b0, m_notrill, "[null]", "[notrill]")); # notrill is better than null
  (modcmp_full_notrill <- brms_compare_models(m_full, m_notrill, "[full]", "[notrill]")); # very mixed results
  (modcmp_original_notrill <- brms_compare_models(m_original, m_notrill, "[original]", "[notrill]")); # they are relatively equivalent but with a hint that notrill is better
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]")); # they are equivalent
  # -> so, Trill is not needed aparently...

  
  # model comparison with the model without Language as random effect:
  (modcmp_original_LnoL <- brms_compare_models(m_original, xling_brm_omnibus_mod_r_revision_results$original$model, "[with Language]", "[without Language]")); # seem equivalent with a hint that with Language is better
  (modcmp_full_LnoL <- brms_compare_models(m_full, xling_brm_omnibus_mod_r_revision_results$full$model, "[with Language]", "[without Language]")); # seem equivalent with a hint that with Language is better

  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough * Trill +
                     (1 + rough * Trill | Language) +
                     (1 + rough * Trill | Family) +
                     (1 + rough * Trill | Area),
                   data=data_full_revised,
                   family="bernoulli",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(m_full, b1f, "[custom prior]", "[default prior]")); # contradicting results, but seem comparable...

  
  xling_brm_omnibus_mod_r_revision_langrand_results <- list("full"=list("model"=NULL, #m_full, # needed for later comparisons
                                                                        "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                                                        "cmp_to_null"=modcmp_0_full, "cmp_no_Language"=modcmp_full_LnoL, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                                                            "original"=list("model"=NULL, #m_original, # needed for later comparisons
                                                                            "summary"=summary_mod_original, "hypotheses"=hyps_original, "hdi95"=hdi95_original, 
                                                                            "cmp_to_null"=modcmp_0_original,  "cmp_to_full"=modcmp_full_original, "cmp_to_noLanguage"=modcmp_original_LnoL,
                                                                            "probs"=probs_original, "probs_text"=probs_text_original, "plot_prefix"=plot_prefix_original),
                                                            "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                                                         "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                                                         "cmp_to_null"=modcmp_0_noint,  "cmp_to_full"=modcmp_full_noint, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                                                            "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                                                           "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                                                           "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                                                           "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill),
                                                            "full_default_priors"=list("hypotheses"=hyps_f, "hdi95"=hdi95_f, "modcmp"=modcmp_f));
  
  # save the results we need later on:
  save(xling_brm_omnibus_mod_r_revision_langrand_results, 
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

In contrast with @winter_trilled_2022, here the full model (including the interaction *rough*:*Trill* and its random slope for all three random effects) seems to fit the data at least as well as the model without random slopes for the interaction *rough*:*Trill*: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_results$original$cmp_to_full)`

and the estimates of the effects are quite similar:
<center>![The estimates of the effects in the 'full' model.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

<center>![The estimates of the effects in the 'original' (as per @winter_trilled_2022) model, excluding the random random slope for *Trill* by *Family*.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_results$original$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The full model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

The **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and even if it is clearly much better than the null (`r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_results$full$cmp_to_null)`), it is unclear what fixed effects contribute to this, as formal hypotheses testing and the 95%HIDs do not find any individually formally significant fixed effect, but there is a suggestion that *rough* might matter:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$summary,sep="\n"));
xling_brm_omnibus_mod_r_revision_langrand_results$full$hypotheses;
```

```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$plot_prefix,"_pred.jpg")`){width="4in"}</center>

However, the priors do seem to influence the posterior estimates only a little, as shown by their estimates and 95% HDIs below:
```{r}
cat("Custom priors:\n"); xling_brm_omnibus_mod_r_revision_langrand_results$full$hdi95;
cat("\n\nDefault priors:\n"); xling_brm_omnibus_mod_r_revision_langrand_results$full_default_priors$hdi95;
```

As a reminder, these are the equivalent results for the original model without *Language* as a random effect:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_results$original$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_results$original$plot_prefix,"_pred.jpg")`){width="4in"}</center>

Finally, this model is slightly better than the original one without *Language* as a random effect: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_results$full$cmp_no_Language)`.


Removing the interaction *rough*:*Trill* results in a much poorer fit: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_results$noint$cmp_to_full)`, suggesting that all terms should be maintained.
The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_results$full$probs_text,sep="\n"));
```

As an exercise, the model without the interaction *rough*:*Trill* suggests a significant main effect of *rough* but not of *Trill*:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_results$noint$summary,sep="\n"));
xling_brm_omnibus_mod_r_revision_langrand_results$noint$hypotheses;
```

Thus, including *Language* as a random effect seems warranted both theoretically and in terms of improved fit, and their results are very similar.


### Including the Indo-European languages as well

@winter_trilled_2022 exclude the Indo-European languages from the cross-linguistic analysis as these are analyzed separately in more detail.
While we partially agree with their argument, we believe that this is an important group of languages (not only in terms of numbers, but also in terms of the available information about them), so we decided to perform an analysis that includes them as well.

Capitalizing on the previous analyses, we will also model *Language* as a random effect.

```{r}
# Select the recoded languages with trill:
data_R_revision_trill_rs_ie <- dplyr::filter(data_R_revision_ie, revision=="trilled",
                                             Meaning %in% c("rough","smooth"));

data_r_revision_trill_rs_ie_1 <- data_R_revision_trill_rs_ie %>% 
  dplyr::mutate(Trill=ifelse(revision=="trilled","yes",NA));

# recode as factors:
data_r_revision_trill_rs_ie_1$rough <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_ie_1$rough)+1], levels=c("no", "yes"));
data_r_revision_trill_rs_ie_1$r     <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_ie_1$r)+1],     levels=c("no", "yes"));
data_r_revision_trill_rs_ie_1$l     <- factor(c("no", "yes")[as.numeric(data_r_revision_trill_rs_ie_1$l)+1],     levels=c("no", "yes"));


# Select the recoded languages without trill:
data_R_revision_other_rs_ie <- dplyr::filter(data_R_revision_ie, revision=="other",
                                          Meaning %in% c("rough","smooth"));

data_r_revision_other_rs_ie_1 <- data_R_revision_other_rs_ie %>% 
  dplyr::mutate(Trill=ifelse(revision=="other","no",NA));

# recode as factors:
data_r_revision_other_rs_ie_1$rough <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_ie_1$rough)+1], levels=c("no", "yes"));
data_r_revision_other_rs_ie_1$r     <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_ie_1$r)+1],     levels=c("no", "yes"));
data_r_revision_other_rs_ie_1$l     <- factor(c("no", "yes")[as.numeric(data_r_revision_other_rs_ie_1$l)+1],     levels=c("no", "yes"));


# Select the recoded languages:
data_full_revised_ie <- rough_r_data_ie %>%
  dplyr::filter(!is.na(revision)) %>% 
  dplyr::mutate(Trill=ifelse(revision=="other","no",
                             ifelse(revision=="trilled","yes",NA))) %>% 
  dplyr::filter(Meaning %in% c("rough","smooth"),
                !is.na(Trill));

# recode as factors:
data_full_revised_ie$rough <- factor(c("no", "yes")[as.numeric(data_full_revised_ie$rough)+1], levels=c("no", "yes"));
data_full_revised_ie$r     <- factor(c("no", "yes")[as.numeric(data_full_revised_ie$r)+1],     levels=c("no", "yes"));
data_full_revised_ie$l     <- factor(c("no", "yes")[as.numeric(data_full_revised_ie$l)+1],     levels=c("no", "yes"));
data_full_revised_ie$Trill <- factor(data_full_revised_ie$Trill,                               levels=c("no", "yes"));
```


#### Languages with trills

```{r include=FALSE}
file_name <- "./cached/xling_replic_withr_langrand_ie.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m1 <- glmer(r ~ 1 + rough +
                (1 + rough | Language) + # language is nested within families so no need to include their interaction
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_trill_rs_ie_1,
              family=binomial(), 
              control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # singular fit
  rePCA(m1); summary(m1); # seems to be the Area 
  m2 <- update(m1, . ~ . - (1 + rough | Area) + (1 | Area) - 
                 (1 | Area)); rePCA(m2); summary(m2); anova(m1, m2); # ok, not singular...
  m0 <- update(m2, . ~ . - rough); summary(m0); # singular fit, but probably not very problematic here
  anova(m2, m0); # much better than the null (p=1.172e-11, ΔAIC=-44.02)
  plot_prefix <- "./figures/xling_glmer_rs_logistic_mod_r_revision_ie_langrand";
  plot_model(m2, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_omnibus_mod_r_revision_results <- list("model"=m2, # needed for later comparisons
                                                     "cmp_to_null"=anova(m2, m0), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Language) + # language is nested within families so no need to include their interaction
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_trill_rs_ie_1,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Language) + # language is nested within families so no need to include their interaction
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_trill_rs_ie_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_r_revision_ie_langrand";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) + # language is nested within families so no need to include their interaction
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_trill_rs_ie_1,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95<- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/xling_brm_rs_logistic_mod_r_revision_ie_langrand";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_full_revised, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) + # language is nested within families so no need to include their interaction
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_trill_rs_ie_1,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']")); # + rough clearly better than null
  # --> clear positive effect of 'rough'
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                     (1 + rough | Language) + # language is nested within families so no need to include their interaction
                     (1 + rough | Family) +
                     (1 + rough | Area),
                   data=data_r_revision_trill_rs_ie_1,
                   family="bernoulli",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # virtually identical
  
  
  # save the results we need later on:
  xling_brm_rs_logistic_mod_r_revision_langrand_ie_results <- list("model"=NULL, #b1, # needed for later comparisons
                                                                   "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, 
                                                                   "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix,
                                                                   "cmp_to_default_prior"=modcmp_f, "hdi95__default_prior"=hdi95_f);
  save(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results, 
       xling_glmer_omnibus_mod_r_revision_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

We tried to fit a frequentist model as well (using `glmer`) but we had to remove the random effect of Area to avoid the model being singular:
```{r}
summary(xling_glmer_omnibus_mod_r_revision_results$model);
```

The Bayesian model does **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** show a positive effect of *rough*:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$summary,sep="\n"));
xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$hdi95
```

This is further supported by formal **Bayesian hypothesis testing**:
```{r}
xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$hypotheses;
```

and **model comparison** against the null model without *rough*: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$cmp_to_null)`.

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and the **posterior predictive checks** also seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_r_revision_langrand_ie_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

The priors do not seem to influence the posterior estimates much and formal model comparison between these two priors suggests that they are essentially equivalent.


#### Languages *without* trills

```{r include=FALSE}
file_name <- "./cached/xling_replic_withoutr_langrand_ie.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  #m1 <- glmer(r ~ 1 + rough +
  #              (1 + rough | Language) +
  #              (1 + rough | Family) +
  #              (1 + rough | Area),
  #            data=data_r_revision_other_rs_ie_1,
  #            family=binomial(), 
  #            control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # Error: number of observations (=289) < number of random effects (=292) for term (1 + rough | Language); the random-effects parameters are probably unidentifiable
  m1 <- glmer(r ~ 1 + rough +
                (1 | Language) +
                (1 + rough | Family) +
                (1 + rough | Area),
              data=data_r_revision_other_rs_ie_1,
              family=binomial(), 
              control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # boundary (singular) fit: see help('isSingular')
  rePCA(m1); summary(m1); # seems to be the Area 
  m2 <- update(m1, . ~ . - (1 + rough | Area) + (1 | Area)); rePCA(m2); summary(m2); anova(m1, m2); # ok, not singular...
  m0 <- update(m2, . ~ . - rough); summary(m0); # singular fit, but probably not very problematic here
  anova(m2, m0); # better than the null (p=0.01598, ΔAIC=-3.8)
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_o_revision_langrand_ie_results";
  plot_model(m2, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_rs_logistic_mod_o_revision_langrand_ie_results <- list("model"=m2, # needed for later comparisons
                                                                     "cmp_to_null"=anova(m2, m0), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough +
              (1 + rough | Language) +
              (1 + rough | Family) +
              (1 + rough | Area),
            data=data_r_revision_other_rs_ie_1,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough +
                         (1 + rough | Language) +
                         (1 + rough | Family) +
                         (1 + rough | Area),
                       data=data_r_revision_other_rs_ie_1,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_rs_logistic_mod_o_revision_langrand_ie_results";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_r_revision_other_rs_ie_1,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0")));
  (hdi95<- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/xling_brm_rs_logistic_mod_o_revision_langrand_ie_results";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod <- capture.output(summary(b1));
  probs_text <- capture.output(probs <- logistic_summary(b1, dat=data_r_revision_other_rs_ie_1, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) + # language is nested within families so no need to include their interaction
                    (1 | Family) +
                    (1 | Area),
                  data=data_r_revision_other_rs_ie_1,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  b1 <- brms_fit_indices(b1);
  (modcmp <- brms_compare_models(b0, b1, "[null]", "[+ 'rough']")); # + rough clearly better than null
  # --> clear positive effect of 'rough'
  
  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough +
                     (1 + rough | Language) +
                     (1 + rough | Family) +
                     (1 + rough | Area),
                   data=data_r_revision_other_rs_ie_1,
                   family="bernoulli",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(b1, b1f, "[custom prior]", "[default prior]")); # virtually identical (with a possible advatange for the default prior)
  
  
  # save the results we need later on:
  xling_brm_rs_logistic_mod_o_revision_langrand_ie_results <- list("model"=NULL, #b1, # needed for later comparisons
                                                                   "summary"=summary_mod, "hypotheses"=hyps, "hdi95"=hdi95, "cmp_to_null"=modcmp, 
                                                                   "probs"=probs, "probs_text"=probs_text, "plot_prefix"=plot_prefix,
                                                                   "cmp_to_default_prior"=modcmp_f, "hdi95__default_prior"=hdi95_f);
  save(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results, 
       xling_glmer_rs_logistic_mod_o_revision_langrand_ie_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

We tried to fit a frequentist model as well (using `glmer`) but we had to remove the random slope of *rough* for both Language and Area to avoid the model not converging and being singular:
```{r}
summary(xling_glmer_rs_logistic_mod_o_revision_langrand_ie_results$model);
```

The Bayesian model does **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **results** show a positive effect of *rough*:
<center>![Posterior estimates (medians) with 50% and 90% posterior probability intervals.](`r paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_mcmcestim.jpg")`){width="5in"}</center>
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$summary,sep="\n"));
```

The directional effect (>0) is supported by the formal **Bayesian hypothesis testing**:
```{r}
xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$hypotheses;
```

but **model comparison** against the null model without *rough* does suggests that adding *rough* does make a difference: `r .print.model.comparison(b=xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$cmp_to_null)`.

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and the **posterior predictive checks** also seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_rs_logistic_mod_o_revision_langrand_ie_results$plot_prefix,"_pred.jpg")`){width="4in"}</center>

The priors do not seem to influence the posterior estimates much and formal model comparison between these two priors suggests that they are essentially equivalent.


#### Omnibus analysis

```{r include=FALSE}
file_name <- "./cached/xling_replic_omnibus_langrand_ie.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  #m1 <- glmer(r ~ 1 + rough * Trill +
  #              (1 + rough * Trill | Language) +
  #              (1 + rough * Trill | Family) +
  #              (1 + rough * Trill | Area),
  #            data=data_full_revised_ie,
  #            family=binomial()); 
  # Error: number of observations (=590) < number of random effects (=1164) for term (1 + rough * Trill | Language); the random-effects parameters are probably unidentifiable
  # let's simplify it:
  m1 <- glmer(r ~ 1 + rough * Trill +
                (1 + rough | Language) +
                (1 + rough * Trill | Family) +
                (1 + rough * Trill | Area),
              data=data_full_revised_ie,
              family=binomial(), control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # boundary (singular) fit: see help('isSingular')
  rePCA(m1); summary(m1); # seems to be the Area 
  m2 <- update(m1, . ~ . - (1 + rough * Trill | Family) + (1 + rough + Trill | Family) - 
                 (1 + rough + Trill | Family) +  + (1 + rough | Family) - 
                 (1 + rough * Trill | Area) + (1 + rough + Trill | Area) - 
                 (1 + rough + Trill | Area) + (1 + rough | Area) - 
                 (1 + rough | Language) + (1 | Language) - 
                 (1 + rough | Area) + (1 | Area) - 
                 (1 | Area)); rePCA(m2); summary(m2); anova(m1, m2); # ok, not singular...
  m0 <- glmer(r ~ 1 +
                (1 | Language) +
                (1 | Family) +
                (1 | Area),
              data=data_full_revised_ie,
              family=binomial()); summary(m0); # singular fit, but probably not very problematic here
  anova(m2, m0); # better than the null (p < 2.2e-16, ΔAIC=-97.2)
  # bot it seems the interaction (and maybe even the Trill) do not really matter:
  m3 <- update(m2, . ~ . - rough:Trill); summary(m3); anova(m2, m3); # p=0.2264
  m4 <- update(m3, . ~ . - Trill); summary(m4); anova(m2, m4); # p=0.4806
  # so, indeed, the Trill does not matter!
  plot_prefix <- "./figures/xling_glmer_omnibus_mod_r_revision_langrand_ie";
  plot_model(m4, type="pred", terms="rough"); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  plot_model(m2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_full_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  xling_glmer_omnibus_mod_r_revision_langrand_ie_results <- list("model"=m4, # needed for later comparisons
                                                                 "full_model"=m2,
                                                                 "cmp_to_null"=anova(m4, m0), "cmp_to_full"=anova(m4, m2), "plot_prefix"=plot_prefix);
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(r ~ 1 + rough * Trill +
              (1 + rough * Trill | Language) +
              (1 + rough * Trill | Family) +
              (1 + rough * Trill | Area),
            data=data_full_revised_ie,
            family="bernoulli");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough * Trill | Language) +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised_ie,
                       prior=b1_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_full_ie";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough * Trill | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_ie,
                  prior=b1_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_full_ie";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=data_full_revised_ie, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b1 <- brms_fit_indices(b1);
  m_full <- b1;
  
  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_full_revised_ie,
                  prior=b0_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]")); # full is better than null
  
  
  # following @winter_trilled_2022 observation "When the same model is fitted without by-Family random slopes over Trill, essentially the same results are obtained, but with narrower credible intervals" we also fit a model without these:
  b2_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # no random slppes for Trill by Family
  # prior predictive checks:
  set.seed(314); # for replicability
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_original_ie";
  b_prior <- brms::brm(r ~ 1 + rough * Trill +
                         (1 + rough | Language) +
                         (1 + rough | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised_ie,
                       prior=b2_priors,
                       family="bernoulli",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  set.seed(314); # for replicability
  b2 <- brms::brm(r ~ 1 + rough * Trill +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_ie,
                  prior=b2_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_original <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_original <- hdi(b2, ci=0.95));
  m_original <- b2;
  # posterior predictive checks
  plot_prefix <- plot_prefix_original <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_original_ie";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_original <- capture.output(summary(b2));
  probs_text_original <- capture.output(probs_original <- logistic_summary(b2, dat=data_full_revised_ie, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_original <- brms_fit_indices(m_original);
  (modcmp_0_original <- brms_compare_models(b0, m_original, "[null]", "[original]")); # original is better than null
  (modcmp_full_original <- brms_compare_models(m_full, m_original, "[full]", "[original]")); # they seem at least identical, but the results are confusing...
  # -> no reason to pick the original over the full here...
  
  
  ## check if Trill:rough really matters (because it seems it might not):
  b3_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area")
  ); # no interaction
  set.seed(314); # for replicability
  b3 <- brms::brm(r ~ 1 + rough + Trill +
                    (1 + rough + Trill | Language) +
                    (1 + rough + Trill | Family) +
                    (1 + rough + Trill | Area),
                  data=data_full_revised_ie,
                  prior=b3_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_noint <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0")));
  (hdi95_noint <- hdi(b3, ci=0.95));
  m_noint <- b3;
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_noint_ie";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b3));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b3, dat=data_full_revised_ie, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_noint <- brms_fit_indices(m_noint);
  (modcmp_0_noint <- brms_compare_models(b0, m_noint, "[null]", "[noint]")); # noint is better than null
  (modcmp_full_noint <- brms_compare_models(m_full, m_noint, "[full]", "[noint]")); # they seem largely equivalent with a hint that full is better
  (modcmp_original_noint <- brms_compare_models(m_original, m_noint, "[original]", "[noint]")); # they are mostly equivalent, probably with a slight advavtage for original
  # -> we can probably remove the interaction Trill:rough...


  # check if Trill is needed at all (because it seems it might not):
  b4_priors <- c(
    set_prior("student_t(5,0,2.5)", class = "b"),
    set_prior("student_t(5,0,2.5)", class = "Intercept"),
    set_prior("lkj(2)", class = "cor"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Language"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Family"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # no Trill
  set.seed(314); # for replicability
  b4 <- brms::brm(r ~ 1 + rough +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_full_revised_ie,
                  prior=b4_priors,
                  family="bernoulli",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b4); mcmc_plot(b4, type="trace"); mcmc_plot(b4);
  (hyps_notrill <- brms::hypothesis(b4, c("roughyes = 0", "roughyes > 0")));
  (hdi95_notrill <- hdi(b4, ci=0.95));
  m_notrill <- b4;
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/xling_brm_omnibus_mod_r_revision_langrand_notrill_ie";
  mcmc_plot(b4, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b4); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b4, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b4));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b4, dat=data_full_revised_ie, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b4, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b4, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b4, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b4, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_notrill <- brms_fit_indices(m_notrill);
  (modcmp_0_notrill <- brms_compare_models(b0, m_notrill, "[null]", "[notrill]")); # notrill is better than null
  (modcmp_full_notrill <- brms_compare_models(m_full, m_notrill, "[full]", "[notrill]")); # very mixed results
  (modcmp_original_notrill <- brms_compare_models(m_original, m_notrill, "[original]", "[notrill]")); # they are relatively equivalent but with a hint that notrill is better
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]")); # they are equivalent but no trill might be better
  # -> so, Trill is not needed apparently...

  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(r ~ 1 + rough * Trill +
                     (1 + rough * Trill | Language) +
                     (1 + rough * Trill | Family) +
                     (1 + rough * Trill | Area),
                   data=data_full_revised_ie,
                   family="bernoulli",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(m_full, b1f, "[custom prior]", "[default prior]")); # contradicting results, but seem comparable...
  
  
  # save the results:
  xling_brm_omnibus_mod_r_revision_langrand_ie_results <- list("full"=list("model"=NULL, #m_full, # needed for later comparisons
                                                                           "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                                                           "cmp_to_null"=modcmp_0_full, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                                                               "original"=list("model"=NULL, #m_original, # needed for later comparisons
                                                                               "summary"=summary_mod_original, "hypotheses"=hyps_original, "hdi95"=hdi95_original, 
                                                                               "cmp_to_null"=modcmp_0_original,  "cmp_to_full"=modcmp_full_original,
                                                                               "probs"=probs_original, "probs_text"=probs_text_original, "plot_prefix"=plot_prefix_original),
                                                               "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                                                            "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                                                            "cmp_to_null"=modcmp_0_noint,  "cmp_to_full"=modcmp_full_noint, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                                                               "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                                                              "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                                                              "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                                                              "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill),
                                                               "full_default_priors"=list("hypotheses"=hyps_f, "hdi95"=hdi95_f, "modcmp"=modcmp_f));
  save(xling_brm_omnibus_mod_r_revision_langrand_ie_results,
       xling_glmer_omnibus_mod_r_revision_langrand_ie_results,
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

We tried to fit a frequentist model as well (using `glmer`) but we had to simplify the random effects structure to avoid the model not converging and being singular:
```{r}
summary(xling_glmer_omnibus_mod_r_revision_langrand_ie_results$full_model);
```
Interestingly, manual simplification suggests that Trill does not matter at all, resulting in a much simpler model:
```{r}
summary(xling_glmer_omnibus_mod_r_revision_langrand_ie_results$model);
```
that is much better than than the null model:
```{r}
xling_glmer_omnibus_mod_r_revision_langrand_ie_results$cmp_to_null;
```
and equivalent to the full:
```{r}
xling_glmer_omnibus_mod_r_revision_langrand_ie_results$cmp_to_full;
```

In the Bayesian approach, in contrast with @winter_trilled_2022, here the full model (including the interaction *rough*:*Trill* and its random slope for all three random effects) seems to fit the data at least as well as the model without random slopes for the interaction *rough*:*Trill*: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_ie_results$original$cmp_to_full)`

and the estimates of the effects are quite similar:
<center>![The estimates of the effects in the 'full' model.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

<center>![The estimates of the effects in the 'original' (as per @winter_trilled_2022) model, excluding the random random slope for *Trill* by *Family*.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$original$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The full model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

The **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

and even if it is clearly much better than the null (`r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$cmp_to_null)`), it is unclear what fixed effects contribute to this, as formal hypotheses testing and the 95%HIDs do not find any individually formally significant fixed effect, but there is a suggestion that *rough* might matter:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$summary,sep="\n"));
xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$hypotheses;
```

```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_pred.jpg")`){width="4in"}</center>

However, the priors do seem to influence the posterior estimates only a little, as shown by their estimates and 95% HDIs below:
```{r}
cat("Custom priors:\n"); xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$hdi95;
cat("\n\nDefault priors:\n"); xling_brm_omnibus_mod_r_revision_langrand_ie_results$full_default_priors$hdi95;
```

Removing the interaction *rough*:*Trill* results in a poorer fit: `r .print.model.comparison(b=xling_brm_omnibus_mod_r_revision_langrand_ie_results$noint$cmp_to_full)`, suggesting that all terms should be maintained.
The **model predictions** are:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$probs_text,sep="\n"));
```
<center>![The effect of the predictors on the probability of *r*.](`r paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$full$plot_prefix,"_pred.jpg")`){width="4in"}</center>

As an exercise, the model without the interaction *rough*:*Trill* suggests a significant main effect of *rough* but not of *Trill*:
```{r results='markup'}
cat(paste0(xling_brm_omnibus_mod_r_revision_langrand_ie_results$noint$summary,sep="\n"));
xling_brm_omnibus_mod_r_revision_langrand_ie_results$noint$hypotheses;
```


### Does word length explain the relationship?

Here we check if word length is the actual cause of the observed correlation.
Please note that to we did the following:

- we first created a "clean form" that is the form with the following characters removed: [0-9.ː:;,-_#&] ⁰¹²³⁴⁵⁶⁷⁸⁹ʰʲʸʷⁿˀˤᵐ (and spaces); duplicate characters are reduced to a single character; for some forms there are two alternative pronunciations but we kept the first one. For example, th form kʰaikʰajá has the "clean form" kaikajá,
- the length of this "clean form" is an *approximation* because of the variation across scripts and transcriptions; the length of the clean form above is 7.

```{r}
# Try to load the data:
if( !file.exists("./data/rough_r_data_IE_length.csv") )
{
  stop("Please first run the Ptyhon script ./ComputeFormLength/ComputeFormLength.py to generate the file ./data/rough_r_data_IE_length.csv!");
}
data_full_revised_allmeanings_ie_length <- read.csv("./data/rough_r_data_IE_length.csv");

# Select the recoded languages:
data_full_revised_allmeanings_ie_length <- data_full_revised_allmeanings_ie_length %>%
  dplyr::filter(!is.na(revision)) %>% 
  dplyr::mutate(Trill=ifelse(revision=="other","no",
                             ifelse(revision=="trilled","yes",NA))) %>% 
  dplyr::filter(!is.na(Trill));

# recode as factors:
data_full_revised_allmeanings_ie_length$rough <- factor(c("no", "yes")[as.numeric(data_full_revised_allmeanings_ie_length$rough == "True")+1], levels=c("no", "yes"));
data_full_revised_allmeanings_ie_length$Trill <- factor(data_full_revised_allmeanings_ie_length$Trill,                               levels=c("no", "yes"));

# Let's see if there's any difference in word length between "rough" and "smooth":
hist(data_full_revised_allmeanings_ie_length$CleanFormLength); # seems count to me -> Poisson regression but we need to subtract the minimum length to make it really Poisson:
data_full_revised_allmeanings_ie_length$cfl2 <- (data_full_revised_allmeanings_ie_length$CleanFormLength - min(data_full_revised_allmeanings_ie_length$CleanFormLength, na.rm=TRUE));

# the 'strict' meanings:
data_full_revised_ie_length <- merge(data_full_revised_ie, 
                                     unique(data_full_revised_allmeanings_ie_length[ data_full_revised_allmeanings_ie_length$Meaning %in% c("rough","smooth"), c("Language", "ISO_code", "Form", "CleanForm", "CleanFormLength", "cfl2")]), 
                                     by=c("Language", "ISO_code", "Form"), all.x=TRUE, all.y=FALSE); # CleanFormLength is a rough estimation of word length
```

#### Using all meanings and froms

The distribution of the clear form length for all meanings is:

```{r fig.width=3*5, fig.height=5, fig.cap=capFig("Distribution of clear form length overall (left), by 'rough' (center) and by 'trill' (right).")}
grid.arrange(ggplot(data_full_revised_allmeanings_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, color="black", fill="gray80") + 
               NULL,
             ggplot(data_full_revised_allmeanings_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, aes(fill=rough), alpha=0.5, color="black") + 
               NULL,
             ggplot(data_full_revised_allmeanings_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, aes(fill=Trill), alpha=0.5, color="black") + 
               NULL, 
             ncol=3);
```

suggesting a Poisson (count) model.
Please note that we subtract the minimum clean form length (=`r min(data_full_revised_allmeanings_ie_length$CleanFormLength, na.rm=TRUE)`) to make it compatible with the Poisson (i.e., starting at 0).

```{r include=FALSE}
file_name <- "./cached/formlength_rough_trill.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  m_full <- glmer(cfl2 ~ 1 + rough * Trill +
                    (1 + rough * Trill | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_allmeanings_ie_length,
                  family=poisson(), 
                  control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # the full model -> boundary (singular) fit
  rePCA(m_full); summary(m_full);
  m1 <- update(m_full, . ~ . - (1 + rough * Trill | Language) + (1 + rough + Trill | Language) - 
                 (1 + rough * Trill | Family) + (1 + rough + Trill | Family) - 
                 (1 + rough * Trill | Area) + (1 + rough + Trill | Area) - 
                 (1 + rough + Trill | Family) + (1 + rough | Family) - 
                 (1 + rough + Trill | Language) + (1 + rough | Language) - 
                 (1 + rough | Language) + (1 | Language) - 
                 (1 + rough + Trill | Area) + (1 + rough | Area) - 
                 (1 + rough | Family) + (1 | Family) - 
                 (1 + rough | Area) + (1 | Area) - 
                 (1 | Area)); rePCA(m1); summary(m1); anova(m1, m_full);
  m2 <- update(m1, . ~ . - rough:Trill); summary(m2); anova(m2, m1); # the interaction does not matter (p=0.56)
  m3 <- update(m2, . ~ . - Trill); summary(m3); anova(m3, m1); # Trill does not matter (p=0.69)
  m0 <- update(m3, . ~ . - rough); summary(m0); # the null model
  # so, only rough has a positive effect on the length...
  formlength_rough_trill_glmer <- list("model"=m3, "full_model"=m1, 
                                       "cmp_to_null"=anova(m3, m0), "cmp_to_full"=anova(m3, m1));
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(cfl2 ~ 1 + rough * Trill +
              (1 + rough * Trill | Language) +
              (1 + rough * Trill | Family) +
              (1 + rough * Trill | Area),
            data=data_full_revised_allmeanings_ie_length,
            family="poisson");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(cfl2 ~ 1 + rough * Trill +
                         (1 + rough * Trill | Language) +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised_allmeanings_ie_length,
                       prior=b1_priors,
                       family="poisson",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/formlength_rough_trill_full";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('form length') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('form length') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('form length') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(cfl2 ~ 1 + rough * Trill +
                    (1 + rough * Trill | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_allmeanings_ie_length,
                  prior=b1_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/formlength_rough_trill_full";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1, variable="^b_", regex=TRUE); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=data_full_revised_allmeanings_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b1 <- brms_fit_indices(b1);
  m_full <- b1;

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(cfl2 ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_full_revised_allmeanings_ie_length,
                  prior=b0_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]")); # full is probably better than null, but very similar in fact
  
  # let's see if the interaction matters:
  b2_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Area")
  ); # no interaction
  set.seed(314); # for replicability
  b2 <- brms::brm(cfl2 ~ 1 + rough + Trill +
                    (1 + rough + Trill | Language) +
                    (1 + rough + Trill | Family) +
                    (1 + rough + Trill | Area),
                  data=data_full_revised_allmeanings_ie_length,
                  prior=b2_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_noint <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0")));
  (hdi95_noint <- hdi(b2, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/formlength_rough_trill_full_noint";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b2));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b2, dat=data_full_revised_allmeanings_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b2 <- brms_fit_indices(b2);
  m_noint <- b2;

  # check if Trill is needed at all (because it seems it might not):
  b3_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area")
  ); # no trill
  set.seed(314); # for replicability
  b3 <- brms::brm(cfl2 ~ 1 + rough +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_full_revised_allmeanings_ie_length,
                  prior=b3_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_notrill <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0")));
  (hdi95_notrill <- hdi(b3, ci=0.95));
  m_notrill <- b3;
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/formlength_rough_trill_full_notrill";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b3));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b3, dat=data_full_revised_allmeanings_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_notrill <- brms_fit_indices(m_notrill);
  (modcmp_0_notrill <- brms_compare_models(b0, m_notrill, "[null]", "[notrill]")); # notrill is better than null
  (modcmp_full_notrill <- brms_compare_models(m_full, m_notrill, "[full]", "[notrill]")); # mixed results, but notrill seems better
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]")); # they are equivalent
  # -> so, Trill is not needed apparently...

  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(cfl2 ~ 1 + rough * Trill +
                     (1 + rough * Trill | Language) +
                     (1 + rough * Trill | Family) +
                     (1 + rough * Trill | Area),
                   data=data_full_revised_allmeanings_ie_length,
                   family="poisson",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(m_full, b1f, "[custom prior]", "[default prior]")); # contradicting results, but seem comparable...
  
  # save the results:
  formlength_rough_trill <- list("full"=list("model"=NULL, #m_full, # needed for later comparisons
                                             "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                             "cmp_to_null"=modcmp_0_full, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                                 "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                              "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                              "cmp_to_null"=modcmp_0_full,  "cmp_to_full"=modcmp_full_noint, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                                 "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                                "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                                "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                                "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill),
                                 "full_default_priors"=list("hypotheses"=hyps_f, "hdi95"=hdi95_f, "modcmp"=modcmp_f));
  
  save(formlength_rough_trill, 
       formlength_rough_trill_glmer,
       file=file_name, compress="xz", compression_level=9); # save this model
  
} else
{
  load(file_name);
}
```

We regressed (Poisson model) first the *clean form length* for *all* meanings (i.e., not just nominally 'rough' and 'smooth') on *trill*, *rough* and their interaction, but the model is arguably not much better than the null model: `r .print.model.comparison(b=formlength_rough_trill$full$cmp_to_null)`

and the estimates of the effects are:
<center>![The estimates of the effects in the 'full' model.](`r paste0(formlength_rough_trill$full$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>
<center>![The effect of the predictors in the 'full' model.](`r paste0(formlength_rough_trill$full$plot_prefix,"_pred.jpg")`){width="4in"}</center>
```{r}
formlength_rough_trill$full$summary;
```

with their formal hypotheses testing and the 95%HIDs:
```{r results='markup'}
formlength_rough_trill$full$hypotheses;
```

The **prior predictive checks** support the choice of priors:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(formlength_rough_trill$full$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The full model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(formlength_rough_trill$full$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **posterior predictive checks** seem ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(formlength_rough_trill$full$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(formlength_rough_trill$full$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The priors have a very small effect, as shown by their estimates and 95% HDIs below:
```{r}
cat("Custom priors:\n"); formlength_rough_trill$full$hdi95;
cat("\n\nDefault priors:\n"); formlength_rough_trill$full_default_priors$hdi95;
```

The fixed effects suggest that only rough might have an effect, which is supported by fitting a model without the interaction `r .print.model.comparison(b=formlength_rough_trill$noint$cmp_to_full)`:
```{r results='markup'}
formlength_rough_trill$noint$hypotheses;
```

and by fitting a model without *trill* `r .print.model.comparison(b=formlength_rough_trill$notrill$cmp_to_noint)`:
```{r results='markup'}
formlength_rough_trill$notrill$hypotheses;
```

Moreover, this model is also better than the null: `r .print.model.comparison(b=formlength_rough_trill$notrill$cmp_to_null)`.

We also performed the same exercise in a frequentist context using `glmer(...,family=poisson())`, but in order to achieve convergence and non-singularity we had to simplify the random effects structure to random intercepts only for Language and Family; further manual simplification shows that only *rough* has an effect:
```{r}
summary(formlength_rough_trill_glmer$model);
```
which is better than the null model:
```{r}
formlength_rough_trill_glmer$cmp_to_null
```
and equivalent to the full model:
```{r}
formlength_rough_trill_glmer$cmp_to_full
```


Thus, we can conclude that it seems that the forms associated with 'rough' (in general) tend to be slightly longer than those associated with 'smooth'.
Let's see what happens when looking only at the strict 'rough' and 'smooth' meanings. 


#### Using only the forms for 'rough' and 'smooth'

Focusing only on the strict 'rough' and 'smooth' words, the distribution of the clear form length for all meanings is:

```{r fig.width=3*5, fig.height=5, fig.cap=capFig("Distribution of clear form length overall (left), by 'rough' (center) and by 'trill' (right) for the strict 'rough' and 'smooth' meanings only.")}
grid.arrange(ggplot(data_full_revised_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, color="black", fill="gray80") + 
               NULL,
             ggplot(data_full_revised_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, aes(fill=rough), alpha=0.5, color="black") + 
               NULL,
             ggplot(data_full_revised_ie_length, aes(CleanFormLength)) + 
               geom_histogram(binwidth=1, aes(fill=Trill), alpha=0.5, color="black") + 
               NULL, 
             ncol=3);
```

suggesting a Poisson (count) model.
As above, we subtract the minimum clean form length (=`r min(data_full_revised_ie_length$CleanFormLength, na.rm=TRUE)`) to make it compatible with the Poisson (i.e., starting at 0).


```{r include=FALSE}
file_name <- "./cached/formlength_rough_trill_strict.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  ## Frequentist ##
  set.seed(314); # for replicability
  #m_full <- glmer(cfl2 ~ 1 + rough * Trill +
  #                  (1 + rough * Trill | Language) +
  #                  (1 + rough * Trill | Family) +
  #                  (1 + rough * Trill | Area),
  #                data=data_full_revised_ie_length,
  #                family=poisson(), 
  #                control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # Error: number of observations (=590) < number of random effects (=1164) for term (1 + rough * Trill | Language); the random-effects parameters are probably unidentifiable
  #m_full <- glmer(cfl2 ~ 1 + rough * Trill +
  #                  (1 + rough + Trill | Language) +
  #                  (1 + rough * Trill | Family) +
  #                  (1 + rough * Trill | Area),
  #                data=data_full_revised_ie_length,
  #                family=poisson(), 
  #                control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # Error: number of observations (=590) < number of random effects (=873) for term (1 + rough + Trill | Language); the random-effects parameters are probably unidentifiable
  m_full <- glmer(cfl2 ~ 1 + rough * Trill +
                    (1 + rough | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_ie_length,
                  family=poisson(), 
                  control=glmerControl(optCtrl=list(maxfun=2e4), optimizer="bobyqa")); # boundary (singular) fit: see help('isSingular')
  rePCA(m_full); summary(m_full);
  m1 <- update(m_full, . ~ . - (1 + rough * Trill | Area) + (1 + rough + Trill | Area) - 
                 (1 + rough * Trill | Family) + (1 + rough + Trill | Family) - 
                 (1 + rough + Trill | Area) + (1 + rough | Area) - 
                 (1 + rough + Trill | Family) + (1 + rough | Family) - 
                 (1 + rough | Area) + (1 | Area) - 
                 (1 + rough | Family) + (1 | Family) - 
                 (1 + rough | Language) + (1 | Language) - 
                 (1 | Area)); rePCA(m1); summary(m1); anova(m1, m_full);
  m2 <- update(m1, . ~ . - rough:Trill); summary(m2); anova(m2, m1); # the interaction does not matter (p=0.99)
  m3 <- update(m2, . ~ . - Trill); summary(m3); anova(m3, m1); # Trill does not matter (p=0.92)
  m0 <- update(m3, . ~ . - rough); summary(m0); # the null model
  # so, only rough has a positive effect on the length...
  formlength_rough_trill_strict_glmer <- list("model"=m3, "full_model"=m1, 
                                              "cmp_to_null"=anova(m3, m0), "cmp_to_full"=anova(m3, m1));
  
  
  ## Bayesian ##
  # check the priors that we can set:
  get_prior(cfl2 ~ 1 + rough * Trill +
              (1 + rough * Trill | Language) +
              (1 + rough * Trill | Family) +
              (1 + rough * Trill | Area),
            data=data_full_revised_ie_length,
            family="poisson");
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(cfl2 ~ 1 + rough * Trill +
                         (1 + rough * Trill | Language) +
                         (1 + rough * Trill | Family) +
                         (1 + rough * Trill | Area),
                       data=data_full_revised_ie_length,
                       prior=b1_priors,
                       family="poisson",
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/formlength_rough_trill_strict";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('form length') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('form length') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('form length') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off but not much)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(cfl2 ~ 1 + rough * Trill +
                    (1 + rough * Trill | Language) +
                    (1 + rough * Trill | Family) +
                    (1 + rough * Trill | Area),
                  data=data_full_revised_ie_length,
                  prior=b1_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/formlength_rough_trill_strict";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1, variable="^b_", regex=TRUE); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=data_full_revised_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b1 <- brms_fit_indices(b1);
  m_full <- b1;

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(cfl2 ~ 1 +
                    (1 | Language) +
                    (1 | Family) +
                    (1 | Area),
                  data=data_full_revised_ie_length,
                  prior=b0_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]")); # full is better than null
  
  # let's see if the interaction matters:
  b2_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Trillyes", group="Area")
  ); # no interaction
  set.seed(314); # for replicability
  b2 <- brms::brm(cfl2 ~ 1 + rough + Trill +
                    (1 + rough + Trill | Language) +
                    (1 + rough + Trill | Family) +
                    (1 + rough + Trill | Area),
                  data=data_full_revised_ie_length,
                  prior=b2_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_noint <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0")));
  (hdi95_noint <- hdi(b2, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/formlength_rough_trill_strict_noint";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b2));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b2, dat=data_full_revised_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b2 <- brms_fit_indices(b2);
  m_noint <- b2;

  # check if Trill is needed at all (because it seems it might not):
  b3_priors <- c(
    brms::set_prior("normal(0, 0.5)", class = "b"),
    brms::set_prior("normal(0, 0.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Language"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Family"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("normal(0, 0.5)", class = "sd", coef = "roughyes", group="Area")
  ); # no trill
  set.seed(314); # for replicability
  b3 <- brms::brm(cfl2 ~ 1 + rough +
                    (1 + rough | Language) +
                    (1 + rough | Family) +
                    (1 + rough | Area),
                  data=data_full_revised_ie_length,
                  prior=b3_priors,
                  family="poisson",
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_notrill <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0")));
  (hdi95_notrill <- hdi(b3, ci=0.95));
  m_notrill <- b3;
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/formlength_rough_trill_strict_notrill";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b3));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b3, dat=data_full_revised_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  # model comparisons
  m_notrill <- brms_fit_indices(m_notrill);
  (modcmp_0_notrill <- brms_compare_models(b0, m_notrill, "[null]", "[notrill]")); # notrill is better than null
  (modcmp_full_notrill <- brms_compare_models(m_full, m_notrill, "[full]", "[notrill]")); # mixed results, but notrill seems better
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]")); # they are equivalent
  # -> so, Trill is not needed apparently...

  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b1f <- brms::brm(cfl2 ~ 1 + rough * Trill +
                     (1 + rough * Trill | Language) +
                     (1 + rough * Trill | Family) +
                     (1 + rough * Trill | Area),
                   data=data_full_revised_ie_length,
                   family="poisson",
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1f); mcmc_plot(b1f, type="trace"); mcmc_plot(b1f);
  (hyps_f <- brms::hypothesis(b1f, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0")));
  (hdi95_f <- hdi(b1f, ci=0.95));
  pp_check(b1f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b1f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b1f <- brms_fit_indices(b1f);
  (modcmp_f <- brms_compare_models(m_full, b1f, "[custom prior]", "[default prior]")); # contradicting results, but seem comparable...
  
  # save the results:
  formlength_rough_trill_strict <- list("full"=list("model"=NULL, #m_full, # needed for later comparisons
                                             "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                             "cmp_to_null"=modcmp_0_full, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                                 "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                              "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                              "cmp_to_null"=modcmp_0_full,  "cmp_to_full"=modcmp_full_noint, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                                 "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                                "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                                "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                                "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill),
                                 "full_default_priors"=list("hypotheses"=hyps_f, "hdi95"=hdi95_f, "modcmp"=modcmp_f));
  
  save(formlength_rough_trill_strict, 
       formlength_rough_trill_strict_glmer,
       file=file_name, compress="xz", compression_level=9); # save this model
  } else
{
  load(file_name);
}
```

As above, we regressed (Poisson model) first the *clean form length* only for 'rough' and 'smooth' on *trill*, *rough* and their interaction, and the best model is the one including only *rough*:

- versus the "full" model: `r .print.model.comparison(b=formlength_rough_trill_strict$notrill$cmp_to_full)`
- versus the model with *trill* and *rough* as main effects: `r .print.model.comparison(b=formlength_rough_trill_strict$notrill$cmp_to_noint)`.

and is better than the null: `r .print.model.comparison(b=formlength_rough_trill_strict$notrill$cmp_to_null)`.

The estimates of the effects are:
<center>![The estimates of the effects in the 'no trill' model.](`r paste0(formlength_rough_trill_strict$notrill$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>
<center>![The effect of the predictors in the 'no trill' model.](`r paste0(formlength_rough_trill_strict$notrill$plot_prefix,"_pred.jpg")`){width="4in"}</center>
```{r results='markup'}
formlength_rough_trill_strict$notrill$summary;
```

with their formal hypotheses testing and the 95%HIDs:
```{r results='markup'}
formlength_rough_trill_strict$notrill$hypotheses;
```

The **prior predictive checks** support the choice of priors (using the full model):
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(formlength_rough_trill_strict$full$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(formlength_rough_trill_strict$full$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **posterior predictive checks** seem almost ok:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(formlength_rough_trill_strict$full$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(formlength_rough_trill_strict$full$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The priors have a very small effect, as shown by their estimates and 95% HDIs below (using the full model):
```{r}
cat("Custom priors:\n"); formlength_rough_trill_strict$full$hdi95;
cat("\n\nDefault priors:\n"); formlength_rough_trill_strict$full_default_priors$hdi95;
```

We also performed the same exercise in a frequentist context using `glmer(...,family=poisson())`, but in order to achieve convergence and non-singularity we had to simplify the random effects structure to random intercepts only for Language and Family; further manual simplification shows that only *rough* has an effect:
```{r}
summary(formlength_rough_trill_glmer$model);
```
which is better than the null model:
```{r}
formlength_rough_trill_glmer$cmp_to_null
```
and equivalent to the full model:
```{r}
formlength_rough_trill_glmer$cmp_to_full
```

These suggest that the forms associated with 'rough' are longer than those associated with 'smooth' cross-linguistically.
This suggests that the effect of *rough* on *r* may be mediated by *form length*...


#### Is the effect of *rough* on *r* mediated by *form length*?

```{r}
file_name <- "./cached/bmed_rough_len_r.RData";
if( !file.exists(file_name) )
{
  # cache these results:
  
  # Languages with trill:
  data_full_revised_ie_length_wt <- data_full_revised_ie_length[ data_full_revised_ie_length$revision == "trilled", c("r", "rough", "cfl2", "Language", "Family", "Area")];
  set.seed(314); # for replicability
  bmed_rough_len_r__wt <- brm(bf(r ~ 1 + rough + cfl2 +  (1 + rough + cfl2 | Language) + (1 + rough + cfl2 | Family) + (1 + rough + cfl2 | Area), family="bernoulli") + # outcome
                                bf(cfl2 ~ 1 + rough +  (1 + rough | Language) + (1 + rough | Family) + (1 + rough | Area), family="poisson") + # mediator
                                set_rescor(FALSE),
                              data=data_full_revised_ie_length_wt,
                              save_pars=save_pars(all=TRUE), # needed for Bayes factors
                              sample_prior=TRUE,  # needed for hypotheses tests
                              cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(bmed_rough_len_r__wt); 
  mcmc_plot(bmed_rough_len_r__wt, type="trace"); 
  mcmc_plot(bmed_rough_len_r__wt);
  (bmed_rough_len_r__wt_mediation <- bayestestR::mediation(bmed_rough_len_r__wt)); # no mediated effect
  
  # Languages withOUT trill:
  data_full_revised_ie_length_nt <- data_full_revised_ie_length[ data_full_revised_ie_length$revision == "other", c("r", "rough", "cfl2", "Language", "Family", "Area")];
  set.seed(314); # for replicability
  bmed_rough_len_r__nt <- brm(bf(r ~ 1 + rough + cfl2 +  (1 + rough + cfl2 | Language) + (1 + rough + cfl2 | Family) + (1 + rough + cfl2 | Area), family="bernoulli") + # outcome
                                bf(cfl2 ~ 1 + rough +  (1 + rough | Language) + (1 + rough | Family) + (1 + rough | Area), family="poisson") + # mediator
                                set_rescor(FALSE),
                              data=data_full_revised_ie_length_nt,
                              save_pars=save_pars(all=TRUE), # needed for Bayes factors
                              sample_prior=TRUE,  # needed for hypotheses tests
                              cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(bmed_rough_len_r__nt); 
  mcmc_plot(bmed_rough_len_r__nt, type="trace"); 
  mcmc_plot(bmed_rough_len_r__nt);
  (bmed_rough_len_r__nt_mediation <- bayestestR::mediation(bmed_rough_len_r__nt)); # no effect
  
  # omnibus test:
  data_full_revised_ie_length_omni <- data_full_revised_ie_length[, c("r", "rough", "Trill", "cfl2", "Language", "Family", "Area")];
  set.seed(314); # for replicability
  bmed_rough_len_r__omni <- brm(bf(r ~ 1 + rough + cfl2 +  (1 + rough * Trill + cfl2 | Language) + (1 + rough * Trill + cfl2 | Family) + (1 + rough * Trill + cfl2 | Area), family="bernoulli") + # outcome
                                  bf(cfl2 ~ 1 + rough * Trill +  (1 + rough * Trill | Language) + (1 + rough * Trill | Family) + (1 + rough * Trill | Area), family="poisson") + # mediator
                                  set_rescor(FALSE),
                                data=data_full_revised_ie_length_omni,
                                save_pars=save_pars(all=TRUE), # needed for Bayes factors
                                sample_prior=TRUE,  # needed for hypotheses tests
                                cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(bmed_rough_len_r__omni); 
  mcmc_plot(bmed_rough_len_r__omni, type="trace"); 
  mcmc_plot(bmed_rough_len_r__omni);
  (bmed_rough_len_r__omni_mediation <- bayestestR::mediation(bmed_rough_len_r__omni)); # no mediated effect
  
  
  # save the results we need later on:
  bmed_rough_len_r <- list("with_trills"   =list("summary"=capture.output(summary(bmed_rough_len_r__wt)), "mediation"=bmed_rough_len_r__wt_mediation),
                           "without_trills"=list("summary"=capture.output(summary(bmed_rough_len_r__nt)), "mediation"=bmed_rough_len_r__nt_mediation),
                           "omnibus"       =list("summary"=capture.output(summary(bmed_rough_len_r__omni)), "mediation"=bmed_rough_len_r__omni_mediation));
  save(bmed_rough_len_r, file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}
```

For the languages **with trills**, there is no mediation effect of form length:
```{r results='markup'}
cat(paste0(
  sprintf("Direct Effect (ADE):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median((tmp <- as.data.frame(bmed_rough_len_r$with_trills$mediation))$effect_direct), hdi(tmp$effect_direct, .89)[2], hdi(tmp$effect_direct, .89)[3], 100*rope(tmp$effect_direct, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Indirect Effect (ACME):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_indirect), hdi(tmp$effect_indirect, .89)[2], hdi(tmp$effect_indirect, .89)[3], 100*rope(tmp$effect_indirect, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Mediator Effect:\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_mediator), hdi(tmp$effect_mediator, .89)[2], hdi(tmp$effect_mediator, .89)[3], 100*rope(tmp$effect_mediator, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Total Effect (TE):\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_total), hdi(tmp$effect_total, .89)[2], hdi(tmp$effect_total, .89)[3], 100*rope(tmp$effect_total, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Proportion mediated:\t % .1f%% 89%%HDI [% .1f%%, % .1f%%]", 
          100*median(tmp$proportion_mediated), 100*hdi(tmp$proportion_mediated, .89)[2], 100*hdi(tmp$proportion_mediated, .89)[3]), "\n"));
#bmed_rough_len_r$with_trills$mediation;
```

while for the languages **without trills** there does not seem to any effect at all (or very weak at best):
```{r}
cat(paste0(
  sprintf("Direct Effect (ADE):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median((tmp <- as.data.frame(bmed_rough_len_r$without_trills$mediation))$effect_direct), hdi(tmp$effect_direct, .89)[2], hdi(tmp$effect_direct, .89)[3], 100*rope(tmp$effect_direct, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Indirect Effect (ACME):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_indirect), hdi(tmp$effect_indirect, .89)[2], hdi(tmp$effect_indirect, .89)[3], 100*rope(tmp$effect_indirect, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Mediator Effect:\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_mediator), hdi(tmp$effect_mediator, .89)[2], hdi(tmp$effect_mediator, .89)[3], 100*rope(tmp$effect_mediator, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Total Effect (TE):\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_total), hdi(tmp$effect_total, .89)[2], hdi(tmp$effect_total, .89)[3], 100*rope(tmp$effect_total, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Proportion mediated:\t % .1f%% 89%%HDI [% .1f%%, % .1f%%]", 
          100*median(tmp$proportion_mediated), 100*hdi(tmp$proportion_mediated, .89)[2], 100*hdi(tmp$proportion_mediated, .89)[3]), "\n"));
#bmed_rough_len_r$without_trills$mediation;
```

When putting all languages together (the **omnibus test**), we find again that there is no mediation effect:
```{r}
cat(paste0(
  sprintf("Direct Effect (ADE):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median((tmp <- as.data.frame(bmed_rough_len_r$omnibus$mediation))$effect_direct), hdi(tmp$effect_direct, .89)[2], hdi(tmp$effect_direct, .89)[3], 100*rope(tmp$effect_direct, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Indirect Effect (ACME):\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_indirect), hdi(tmp$effect_indirect, .89)[2], hdi(tmp$effect_indirect, .89)[3], 100*rope(tmp$effect_indirect, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Mediator Effect:\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_mediator), hdi(tmp$effect_mediator, .89)[2], hdi(tmp$effect_mediator, .89)[3], 100*rope(tmp$effect_mediator, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Total Effect (TE):\t\t % .2f 89%%HDI [% .2f, % .2f] %%(89%%HDI inside the [-0.10, 0.10] ROPE)=%.1f%%", 
          median(tmp$effect_total), hdi(tmp$effect_total, .89)[2], hdi(tmp$effect_total, .89)[3], 100*rope(tmp$effect_total, ci=0.89)["ROPE_Percentage"]), "\n",
  sprintf("Proportion mediated:\t % .1f%% 89%%HDI [% .1f%%, % .1f%%]", 
          100*median(tmp$proportion_mediated), 100*hdi(tmp$proportion_mediated, .89)[2], 100*hdi(tmp$proportion_mediated, .89)[3]), "\n"));
#bmed_rough_len_r$omnibus$mediation;
```

Thus, while there might be a difference in length between the forms for "rough" and "smooth" this does not seem to drive the difference between them in the frequency of "r".


### Fine-grained controls

We use here the global phylogeny from @jagerGlobalscalePhylogeneticLinguistic2018 to implement a more fine-graded control for history.
More precisely, the random effects are structured as:

a) the global phylogeny using `(1 + ... | gr(phylo, cov=A))`, where *phylo* is the language's glottocode and *A* is the phylogenetic variance-covariance matrix of the global phylogeny from @jagerGlobalscalePhylogeneticLinguistic2018,
b) as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd, we also use a separate random effect `(1 + ... | glottocode)` to allow multiple observations (i.e., workds and/or meanings) per language, and
c) `(1 + ... | Area)` to control for contact, because 2D Gaussian process does not work for these data :(.

```{r include=FALSE}
library(stringr);
library(ape);

# Map the ISO codes to Glottocodes:
glottolog_data <- read.csv("./data/glottolog/languages_and_dialects_geo.csv");
data_full_revised_ie_length[ grep(";", data_full_revised_ie_length$ISO_code, fixed=TRUE), ]; # two ISO codes
data_full_revised_ie_length$ISO_code[ data_full_revised_ie_length$ISO_code == "ggn; gvr" ] <- "gvr"; # keep the most general one
data_full_revised_ie_length$ISO_code[ data_full_revised_ie_length$ISO_code == "tpg; swt" ] <- "swt"; # seems this is the right language
data_full_revised_ie_length <- merge(data_full_revised_ie_length, glottolog_data[ glottolog_data$isocodes != "", c("isocodes", "glottocode")], by.x="ISO_code", by.y="isocodes", all.x=TRUE, all.y=FALSE);
data_full_revised_ie_length[ is.na(data_full_revised_ie_length$glottocode), ]; # matching errors
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "aze" ] <- "nort2697"; # aze does map on Glottolog -> pick North Azerbaijani
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "bua" ] <- "mong1330"; # bua should map to Mongolia Buriat
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "est" ] <- "esto1258"; # est does map on Glottolog -> pick Estonian
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "jya" ] <- "core1262"; # jya does map on Glottolog -> pick Core Gyalrong
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "mlg" ] <- "mala1537"; # mlg does map on Glottolog -> pick Malagasic
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "mon" ] <- "mong1331"; # mon does map on Glottolog -> pick Mongolian
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "swa" ] <- "swah1253"; # swa does map on Glottolog -> pick Swahili
data_full_revised_ie_length$glottocode[ data_full_revised_ie_length$ISO_code == "uzb" ] <- "uzbe1247"; # uzb does map on Glottolog -> pick Uzbek


# Check the tree (from ape::plot.phylo()):
.check.phylo <- function(tree, verbose=FALSE)
{
  Nedge <- dim(tree$edge)[1];
  Nnode <- tree$Nnode;
  Ntip <- length(tree$tip.label);
  if( Ntip < 2 ) 
  {
    if(verbose) warning("Less than 2 tips in the tree");
    return (FALSE);
  }        
  if( any(tree$edge < 1) || any(tree$edge > Ntip + Nnode) )
  {
    if(verbose) warning("Tree badly conformed");
    return (FALSE);
  }
  return (TRUE); # all seems ok
}


file_name <- "./cached/phylogenies.RData";
if( !all(file.exists(file_name)) )
{
  library(castor);
  
  trees <- list();
  
  
  ## Gerhard Jäger (2018)'s frequentist trees based on ASJP 17:
  # Unpack, read and delete the ASJP language metadata:
  if( !file.exists("./data/phylogenies/Jaeger_2018/asjp-v17.zip") )
  {
    # try to download it:
    download.file("https://zenodo.org/record/3835942/files/lexibank/asjp-v17.zip?download=1", "./data/phylogenies/Jaeger_2018/asjp-v17.zip");
    if( !file.exists("./data/phylogenies/Jaeger_2018/asjp-v17.zip") ) stop("Error retrieveing the ASJP-17 data!");
  }
  unzip("./data/phylogenies/Jaeger_2018/asjp-v17.zip", exdir="./data/phylogenies/Jaeger_2018/");
  asjp_lgs <- read.table("./data/phylogenies/Jaeger_2018/lexibank-asjp-5114ccc/cldf/languages.csv", header=TRUE, sep=",", quote='"');
  asjp_lgs$Name2 <- toupper(str_replace_all(asjp_lgs$Name, fixed("-"), "_")); # - seem systematically replaced by "_" in Gerhard's trees
  asjp_lgs <- rbind(asjp_lgs, asjp_lgs[ asjp_lgs$Name2 == "WEMBAWEMBA", ]); asjp_lgs$Name2[ nrow(asjp_lgs) ] <- "WEMBA_WEMBA"; # in Gerhard's trees it appears also as WEMBA_WEMBA
  unlink("./data/phylogenies/Jaeger_2018/lexibank-asjp-5114ccc", recursive=TRUE);
  
  # Unpack, read and delete Gerhard's trees:
  if( !file.exists("./data/phylogenies/Jaeger_2018/trees.zip") )
  {
    stop("Please download the 'trees' subfolder of the https://osf.io/cufv7/ OSF repository ( DOI 10.17605/OSF.IO/CUFV7) as ZIP file!");
  }
  unzip("./data/phylogenies/Jaeger_2018/trees.zip", exdir="./data/phylogenies/Jaeger_2018/trees/");
  
  # Read and process Gerhard's trees:
  .read.gerhard.tree <- function(tree_name, 
                                 lgs_to_keep=data_full_revised_ie_length$glottocode,
                                 min_n_lgs_per_fam=1)
  {
    # Read the tree:
    if( !file.exists(paste0("./data/phylogenies/Jaeger_2018/trees/",tree_name,".tre")) ) 
    {
      warning(paste0("Tree for '",tree_name,"' was not found!"));
      return (NULL);
    }
    tree <- read.tree(paste0("./data/phylogenies/Jaeger_2018/trees/",tree_name,".tre"));
    if( is.null(tree) ) return (NULL);
    
    # Map the tips to Glottolog codes:
    tree$tip.label <- vapply(tree$tip.label, function(s)
    {
      s.asjp <- toupper(strsplit(s,".",fixed=TRUE)[[1]][3]);
      if( is.null(s.asjp) || is.na(s.asjp) ){ warning(paste0("No ASJP name can be extracted from language '",s,"'.")); return (NA_character_); }
      s.glottolog <- unique(asjp_lgs$Glottocode[ asjp_lgs$Name2 == s.asjp ]);
      if( length(s.glottolog) == 0 ){ warning(paste0("No match found in the ASJP database for language '",s,"'.")); return (NA_character_); }
      if( length(s.glottolog) > 1 ){ warning(paste0("More than one matching Glottolog code found in the ASJP database for language '",s,"': ",paste0(s.glottolog,collapse=", ")," -- picking the first one.")); return (s.glottolog[1]); }
      return (s.glottolog);
    }, character(1));
    
    # Trim the tree to the available data:
    if( !.check.phylo(tree) )
    {
      warning(paste0("The tree for  '",tree_name,"' has well-fromedness issues."));
      return (NULL);
    }
    
    tree <- drop.tip(tree, which(!(tree$tip.label %in% lgs_to_keep)), trim.internal=TRUE);
    if( is.null(tree) ){ warning(paste0("The tree for  '",tree_name,"' is has no data in our database.")); return (NULL); }
    dup.tips <- duplicated(tree$tip.label); # duplicated tips
    tree <- drop.tip(tree, which(dup.tips), trim.internal=TRUE); # drop them and keep the first occurrence
    if( length(tree$tip.label) == 1 ){ warning(paste0("The tree for  '",tree_name,"' is degenerate when intersected with our database.")); return (NULL); }
    if( has.singles(tree) ) tree <- collapse.singles(tree, root.edge=TRUE);
    tree$edge.length[ tree$edge.length <= 0.0 ] <- min(tree$edge.length[ tree$edge.length > 0.0 ], na.rm=TRUE) / 10.0; # make sure there are no 0-length branches
    
    if( length(tree$tip.label) < min_n_lgs_per_fam )
    {
      warning(paste0("The tree for  '",tree_name,"' has less than ",min_n_lgs_per_fam," languages: dropping it."));
      return (NULL);
    }
    
    return (tree);
  }
  
  # Try to load Gerhard's trees:
  tree_names <- list.files("./data/phylogenies/Jaeger_2018/trees/", pattern=glob2rx("*.tre"), all.files=TRUE, full.names=FALSE, recursive=FALSE, include.dirs=FALSE);
  for( tree_name in "world.tre" )
  {
    fam_name <- substring(tree_name, 1, nchar(tree_name)-4);
    fam_name2 <- tolower(str_replace_all(fam_name, fixed("-"),  "_"));
    if( !is.null(tree <- .read.gerhard.tree(fam_name)) )
    {
      cat(paste0("Successfully loaded Gerhard Jäger's tree '",fam_name,"' (as '",fam_name2,"')...\n"));
      if( fam_name2 %in% names(trees) )
      {
        trees[[fam_name2]]$gerhard <- tree;
      } else
      {
        trees[[length(trees)+1]] <- list();
        trees[[length(trees)]]$gerhard <- tree;
        names(trees)[length(trees)] <- fam_name2;
      }
    }
  }
  
  # Delete the temporary folder and files:
  unlink("./data/phylogenies/Jaeger_2018/trees", recursive=TRUE);
  
  
  ## The MCC global phylogeny from Bouckaert et al. (2022):
  b22_tree <- NULL;
  if( !file.exists("./data/phylogenies/Bouckaert_etal_2022/global-language-tree-MCC-labelled.tree.gz") ) 
  {
    # try to download it:
    download.file("https://github.com/rbouckaert/global-language-tree-pipeline/releases/download/v1.0.0/global-language-tree-MCC-labelled.tree.gz", "./data/phylogenies/Bouckaert_etal_2022/global-language-tree-MCC-labelled.tree.gz");
    if( !file.exists("./data/phylogenies/Bouckaert_etal_2022/global-language-tree-MCC-labelled.tree.gz") ) warning("Please download the MCC global phylogeny 'global-language-tree-MCC-labelled.tree.gz' from https://github.com/rbouckaert/global-language-tree-pipeline/releases/ (Release 1.0.0, Jul 10, 2022)");
  }
  if( file.exists("./data/phylogenies/Bouckaert_etal_2022/global-language-tree-MCC-labelled.tree.gz") ) 
  {
    b22_tree <- read.nexus(gzfile("./data/phylogenies/Bouckaert_etal_2022/global-language-tree-MCC-labelled.tree.gz"));
    if( is.null(b22_tree) )
    {
      warning("Issues reading the global tree of Bouckaert et al. (2022).");
    } else
    {
      b22_tree$tip.label <- vapply(b22_tree$tip.label, function(s) substring(s,1,8), character(1)); # keep just the glottocode for the tips
      
      # Trim the tree to the available data:
      if( !.check.phylo(b22_tree) )
      {
        warning(paste0("The global tree of Bouckaert et al. (2022) has well-fromedness issues."));
        return (NULL);
      }
      
      lgs_to_keep=data_full_revised_ie_length$glottocode;
      b22_tree <- drop.tip(b22_tree, which(!(b22_tree$tip.label %in% lgs_to_keep)), trim.internal=TRUE);
      if( is.null(b22_tree) ){ warning(paste0("The global tree of Bouckaert et al. (2022) is has no data in our database.")); b22_tree <- NULL; }
      dup.tips <- duplicated(b22_tree$tip.label); # duplicated tips
      b22_tree <- drop.tip(b22_tree, which(dup.tips), trim.internal=TRUE); # drop them and keep the first occurrence
      if( length(b22_tree$tip.label) == 1 ){ warning(paste0("The global tree of Bouckaert et al. (2022) is degenrate when intersected with our database.")); b22_tree <- NULL; }
      if( has.singles(b22_tree) ) b22_tree <- collapse.singles(b22_tree, root.edge=TRUE);
      b22_tree$edge.length[ b22_tree$edge.length <= 0.0 ] <- min(b22_tree$edge.length[ b22_tree$edge.length > 0.0 ], na.rm=TRUE) / 10.0; # make sure there are no 0-length branches
      
      if( length(b22_tree$tip.label) < 1 )
      {
        warning(paste0("The global tree has less than ",min_n_lgs_per_fam," languages: dropping it."));
        b22_tree <- NULL;
      }

      if( !is.null(b22_tree) )
      {
        # Store it:
        trees$world$betal22 <- b22_tree;
      }
    }
  } else
  {
    warning("Issues reading the global tree of Bouckaert et al. (2022).");
  }
  
  
  # Finally, assemble the various results and save them:
  save(trees, file=file_name, compress="xz", compression_level=9);
} else
{
  load(file_name);
} 
```

```{r include=FALSE}
file_name <- "./cached/worldtree_reg.RData";
if( !file.exists(file_name) ) # all this stuff is **very** computationally expensive!!!
{
  ### collect results:
  b_wt_reg <- list();
  
  # Select and align the data to the tree:
  tree <- trees$world$gerhard;
  d <- unique(data_full_revised_ie_length[ data_full_revised_ie_length$glottocode %in% tree$tip.label, ]);
  d$phylo <- d$glottocode; # duplicate it as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
  d$latitude_r  <- 1.0 - cos(d$Latitude*(pi/180)); # make sure these longitudes are still highest at the poles
  d$longitude_r <- cos(d$Longitude*(pi/180));
  

  # Phylogenetic variance-covariance matrix:
  A <- ape::vcv.phylo(tree);

  # check the priors that we can set:
  get_prior(r ~ 1 + rough * Trill + cfl2 + # the relevant predictors
              (1 + rough * Trill + cfl2 | gr(phylo, cov=A)) + 
              (1 + rough * Trill + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
              (1 + rough * Trill + cfl2 | Area), # area as random effect
            family=bernoulli(link="logit"), 
            data=d, data2=list(A=A));
  # setting the priors:
  b1_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes:Trillyes", group="Area")
  ); # for the full model
  # prior predictive checks:
  set.seed(314); # for replicability
  b_prior <- brms::brm(r ~ 1 + rough * Trill + cfl2 + # the relevant predictors
                         (1 + rough * Trill + cfl2 | gr(phylo, cov=A)) + 
                         (1 + rough * Trill + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                         (1 + rough * Trill + cfl2 | Area), # area as random effect
                       data=d, data2=list(A=A),
                       prior=b1_priors,
                       family=bernoulli(link="logit"), 
                       sample_prior='only',  # needed for prior predictive checks
                       cores=brms_ncores, iter=2000, warmup=1000, thin=2, control=brms_control);
  # save the results we need later on:
  plot_prefix <- "./figures/phylo_full";
  g <- arrangeGrob(pp_check(b_prior, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Prior predictive distribution of minimum values'),
                   pp_check(b_prior, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Prior predictive distribution of means'),
                   pp_check(b_prior, type='stat', stat='max') + xlab('p(r)') + ggtitle('Prior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min, even if the mean is a bit off)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_prior_predictive_checks.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
   
  # fit the logistic model:
  set.seed(314); # for replicability
  b1 <- brms::brm(r ~ 1 + rough * Trill + cfl2 + # the relevant predictors
                    (1 + rough * Trill + cfl2 | gr(phylo, cov=A)) + 
                    (1 + rough * Trill + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                    (1 + rough * Trill + cfl2 | Area), # area as random effect
                  data=d, data2=list(A=A),
                  prior=b1_priors,
                  family=bernoulli(link="logit"),
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b1); mcmc_plot(b1, type="trace"); mcmc_plot(b1);
  (hyps_full <- brms::hypothesis(b1, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "roughyes:Trillyes = 0", "cfl2 = 0")));
  (hdi95_full <- hdi(b1, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_full <- "./figures/phylo_full";
  mcmc_plot(b1, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b1, variable="^b_", regex=TRUE); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b1, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_full <- capture.output(summary(b1));
  probs_text_full <- capture.output(probs_full <- logistic_summary(b1, dat=d, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b1, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b1, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b1, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b1, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b1 <- brms_fit_indices(b1); # extremely slow (2-3 days)
  m_full <- b1;
  # save(b1, file="~/Temp/b1.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...

  # model comparison with the null model:
  b0_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area")
  ); # for the null model
  b0 <- brms::brm(r ~ 1 + # the relevant predictors
                    (1 | gr(phylo, cov=A)) + 
                    (1 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                    (1 | Area), # area as random effect
                  data=d, data2=list(A=A),
                  prior=b0_priors,
                  family=bernoulli(link="logit"),
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b0); 
  mcmc_plot(b0, type="trace"); 
  mcmc_plot(b0);
  b0 <- brms_fit_indices(b0);
  (modcmp_0_full <- brms_compare_models(b0, m_full, "[null]", "[full]", bayes_factor=FALSE)); # full is much better than the null (BFs don't work though)
  # save(b0, file="~/Temp/b0.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...
  
  # let's see if the interaction matters:
  b2_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Trillyes", group="Area")
  ); # no interaction
  set.seed(314); # for replicability
  b2 <- brms::brm(r ~ 1 + rough + Trill + cfl2 + # the relevant predictors
                    (1 + rough + Trill + cfl2 | gr(phylo, cov=A)) + 
                    (1 + rough + Trill + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                    (1 + rough + Trill + cfl2 | Area), # area as random effect
                  data=d, data2=list(A=A),
                  prior=b2_priors,
                  family=bernoulli(link="logit"),
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b2); mcmc_plot(b2, type="trace"); mcmc_plot(b2);
  (hyps_noint <- brms::hypothesis(b2, c("roughyes = 0", "roughyes > 0", "Trillyes = 0", "Trillyes > 0", "cfl2 = 0")));
  (hdi95_noint <- hdi(b2, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_noint <- "./figures/phylo_noint";
  mcmc_plot(b2, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b2); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b2, type="pred", terms=c("rough", "Trill")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_noint <- capture.output(summary(b2));
  probs_text_noint <- capture.output(probs_noint <- logistic_summary(b2, dat=d, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b2, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b2, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b2, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b2, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b2 <- brms_fit_indices(b2);
  m_noint <- b2;
  (modcmp_noint_0    <- brms_compare_models(m_noint, b0,     "[noint]", "[null]", bayes_factor=FALSE)); # noint is much better than the null (BFs don't work though)
  (modcmp_noint_full <- brms_compare_models(m_noint, m_full, "[noint]", "[full]", bayes_factor=FALSE)); # noint and full are equivalent (BFs don't work though)
  # save(b2, file="~/Temp/b2.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...

  # check if Trill is needed at all (because it seems it might not):
  b3_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "cfl2", group="Area")
  ); # no trill
  set.seed(314); # for replicability
  b3 <- brms::brm(r ~ 1 + rough + cfl2 + # the relevant predictors
                    (1 + rough + cfl2 | gr(phylo, cov=A)) + 
                    (1 + rough + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                    (1 + rough + cfl2 | Area), # area as random effect
                  data=d, data2=list(A=A),
                  prior=b3_priors,
                  family=bernoulli(link="logit"),
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3); mcmc_plot(b3, type="trace"); mcmc_plot(b3);
  (hyps_notrill <- brms::hypothesis(b3, c("roughyes = 0", "roughyes > 0", "cfl2 = 0", "cfl2 > 0")));
  (hdi95_notrill <- hdi(b3, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_notrill <- "./figures/phylo_notrill";
  mcmc_plot(b3, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b3); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b3, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_notrill <- capture.output(summary(b3));
  probs_text_notrill <- capture.output(probs_notrill <- logistic_summary(b3, dat=data_full_revised_allmeanings_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b3, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b3, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b3 <- brms_fit_indices(b3);
  m_notrill <- b3;
  # model comparisons
  (modcmp_0_notrill     <- brms_compare_models(b0,      m_notrill, "[null]",  "[notrill]", bayes_factor=FALSE)); # notrill is much better than null
  (modcmp_full_notrill  <- brms_compare_models(m_full,  m_notrill, "[full]",  "[notrill]", bayes_factor=FALSE)); # mixed results, but they seem equivalent
  (modcmp_noint_notrill <- brms_compare_models(m_noint, m_notrill, "[noint]", "[notrill]", bayes_factor=FALSE)); # they are pretty much equivalent
  # save(b3, file="~/Temp/b3.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...
  # -> so, Trill is not needed apparently...

  # check if cfl2 is needed:
  b4_priors <- c(
    brms::set_prior("student_t(5,0,2.5)", class = "b"),
    brms::set_prior("student_t(5,0,2.5)", class = "Intercept"),
    brms::set_prior("lkj(2)", class = "cor"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="glottocode"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="phylo"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "Intercept", group="Area"),
    brms::set_prior("student_t(4,0,2)", class = "sd", coef = "roughyes", group="Area")
  ); # no cfl2
  set.seed(314); # for replicability
  b4 <- brms::brm(r ~ 1 + rough + # the relevant predictors
                    (1 + rough | gr(phylo, cov=A)) + 
                    (1 + rough | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                    (1 + rough | Area), # area as random effect
                  data=d, data2=list(A=A),
                  prior=b4_priors,
                  family=bernoulli(link="logit"),
                  save_pars=save_pars(all=TRUE), # needed for Bayes factors
                  sample_prior=TRUE,  # needed for hypotheses tests
                  cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b4); mcmc_plot(b4, type="trace"); mcmc_plot(b4);
  (hyps_nocfl2 <- brms::hypothesis(b4, c("roughyes = 0", "roughyes > 0")));
  (hdi95_nocfl2 <- hdi(b4, ci=0.95));
  # posterior predictive checks
  plot_prefix <- plot_prefix_nocfl2 <- "./figures/phylo_nocfl2";
  mcmc_plot(b4, type="trace"); ggsave(paste0(plot_prefix,"_mcmctrace.jpg"), device="jpeg", width=7, height=6, units="in", quality=85);
  mcmc_plot(b4); ggsave(paste0(plot_prefix,"_mcmcestim.jpg"), device="jpeg", width=7, height=4, units="in", quality=85);
  plot_model(b4, type="pred", terms=c("rough")); ggsave(paste0(plot_prefix,"_pred.jpg"), device="jpeg", width=4, height=4, units="in", quality=85);
  summary_mod_nocfl2 <- capture.output(summary(b4));
  probs_text_nocfl2 <- capture.output(probs_nocfl2 <- logistic_summary(b4, dat=data_full_revised_allmeanings_ie_length, outcome="/r/", roughpred="rough", true_val="yes", pp_over_zero=TRUE));
  pp_check(b4, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay'); ggsave(paste0(plot_prefix,"_ppcheck_densoverlay.jpg"), device="jpeg", width=6, height=4, units="in", quality=85);
  g <- arrangeGrob(pp_check(b4, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b4, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b4, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g); ggsave(paste0(plot_prefix,"_ppcheck_min_mean_max.jpg"), plot=g, device="jpeg", width=6, height=4*3, units="in", quality=85);
  b4 <- brms_fit_indices(b4);
  m_nocfl2 <- b4;
  # model comparisons
  (modcmp_0_nocfl2       <- brms_compare_models(b0,        m_nocfl2, "[null]",    "[nocfl2]", bayes_factor=FALSE)); # much better than null
  (modcmp_full_nocfl2    <- brms_compare_models(m_full,    m_nocfl2, "[full]",    "[nocfl2]", bayes_factor=FALSE)); # nocfl2 seems worse
  (modcmp_noint_nocfl2   <- brms_compare_models(m_noint,   m_nocfl2, "[noint]",   "[nocfl2]", bayes_factor=FALSE)); # nocfl2 seems worse
  (modcmp_notrill_nocfl2 <- brms_compare_models(m_notrill, m_nocfl2, "[notrill]", "[nocfl2]", bayes_factor=FALSE)); # nocfl2 is worse
  # save(b4, file="~/Temp/b4.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...
  # -> ir seems it makes sense to keep cfl2 after all...
  m_best <- m_notrill;

  
  # compare with the default improper priors (prior sensitivity check):
  set.seed(314); # for replicability
  b3f <- brms::brm(r ~ 1 + rough + cfl2 + # the relevant predictors
                     (1 + rough + cfl2 | gr(phylo, cov=A)) + 
                     (1 + rough + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                     (1 + rough + cfl2 | Area), # area as random effect
                   data=d, data2=list(A=A),
                   family=bernoulli(link="logit"),
                   save_pars=save_pars(all=TRUE), # needed for Bayes factors
                   sample_prior=TRUE,  # needed for hypotheses tests
                   cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(b3f); mcmc_plot(b3f, type="trace"); mcmc_plot(b3f);
  (hyps_f <- brms::hypothesis(b3f, c("roughyes = 0", "roughyes > 0", "cfl2 = 0", "cfl2 > 0")));
  (hdi95_f <- hdi(b3f, ci=0.95));
  pp_check(b3f, ndraws=100) + xlab('p(r)') + ggtitle('Posterior predictive density overlay');
  g <- arrangeGrob(pp_check(b3f, type='stat', sta ='min') + xlab('p(r)') + ggtitle('Posterior predictive distribution of minimum values'),
                   pp_check(b3f, type='stat', stat='mean') + xlab('p(r)') + ggtitle('Posterior predictive distribution of means'),
                   pp_check(b3f, type='stat', stat='max') + xlab('p(r)') + ggtitle('Posterior predictive distribution of maximum values'),
                   ncol=1); # seems fine (the observed, y, does fall in the predicted distributions, y_{rep} for the max, mean and min)
  as_ggplot(g);
  b3f <- brms_fit_indices(b3f);
  (modcmp_f <- brms_compare_models(m_notrill, b3f, "[custom prior]", "[default prior]", bayes_factor=FALSE)); # indistinguishable
  # save(b3f, file="~/Temp/b3f.RData", compress="xz", compression_level=9); # takes a long time to do it and we manually simplify from it, so make a safe copy in case all crashes so we can continue...
  
  
  # Given that the best model seems to be the one with rough + cfl2, let's see if this is not really a mediation model rough -> cfl2 -> r:
  set.seed(314); # for replicability
  bmed_rough_len_r__wt <- brm(bf(r ~ 1 + rough + cfl2 + # the relevant predictors
                                   (1 + rough + cfl2 | gr(phylo, cov=A)) + 
                                   (1 + rough + cfl2 | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                                   (1 + rough + cfl2 | Area),
                                 family=bernoulli(link="logit")) + # outcome
                                bf(cfl2 ~ 1 + rough + 
                                     (1 + rough | gr(phylo, cov=A)) + 
                                     (1 + rough | glottocode) + # the "world" tree allowing multiple observations per language as per https://rdrr.io/cran/brms/f/vignettes/brms_phylogenetics.Rmd
                                     (1 + rough | Area), 
                                   family="poisson") + # mediator
                                set_rescor(FALSE),
                              data=d, data2=list(A=A),
                              save_pars=save_pars(all=TRUE), # needed for Bayes factors
                              sample_prior=TRUE,  # needed for hypotheses tests
                              cores=brms_ncores, iter=brms_iter, warmup=brms_warmup, thin=brms_thin, control=brms_control);
  summary(bmed_rough_len_r__wt); 
  mcmc_plot(bmed_rough_len_r__wt, type="trace"); 
  mcmc_plot(bmed_rough_len_r__wt);
  (bmed_rough_len_r__wt_mediation <- bayestestR::mediation(bmed_rough_len_r__wt)); # no mediated effect
  summary_mediation <- capture.output(summary(bmed_rough_len_r__wt));
  
  
  # save the results:
  worldtree_reg <- list("full"=list("model"=NULL, #m_full, # needed for later comparisons
                                    "summary"=summary_mod_full, "hypotheses"=hyps_full, "hdi95"=hdi95_full, 
                                    "cmp_to_null"=modcmp_0_full, "probs"=probs_full, "probs_text"=probs_text_full, "plot_prefix"=plot_prefix_full),
                        "noint"=list("model"=NULL, #m_noint, # needed for later comparisons
                                     "summary"=summary_mod_noint, "hypotheses"=hyps_noint, "hdi95"=hdi95_noint, 
                                     "cmp_to_null"=modcmp_noint_0,  "cmp_to_full"=modcmp_noint_full, "probs"=probs_noint, "probs_text"=probs_text_noint, "plot_prefix"=plot_prefix_noint),
                        "notrill"=list("model"=NULL, #m_notrill, # needed for later comparisons
                                       "summary"=summary_mod_notrill, "hypotheses"=hyps_notrill, "hdi95"=hdi95_notrill, 
                                       "cmp_to_null"=modcmp_0_notrill,  "cmp_to_full"=modcmp_full_notrill, "cmp_to_noint"=modcmp_noint_notrill, 
                                       "probs"=probs_notrill, "probs_text"=probs_text_notrill, "plot_prefix"=plot_prefix_notrill),
                        "nocfl2"=list("model"=NULL, #m_nocfl2, # needed for later comparisons
                                       "summary"=summary_mod_nocfl2, "hypotheses"=hyps_nocfl2, "hdi95"=hdi95_nocfl2, 
                                       "cmp_to_null"=modcmp_0_nocfl2,  "cmp_to_full"=modcmp_full_nocfl2, "cmp_to_noint"=modcmp_noint_nocfl2, "cmp_to_notrill"=modcmp_notrill_nocfl2,  
                                       "probs"=probs_nocfl2, "probs_text"=probs_text_nocfl2, "plot_prefix"=plot_prefix_nocfl2),
                        "notrill_default_priors"=list("hypotheses"=hyps_f, "hdi95"=hdi95_f, "modcmp"=modcmp_f),
                        "mediation"=list("summary"=summary_mediation, "mediation"=bmed_rough_len_r__wt_mediation));
  
  save(worldtree_reg, 
       file=file_name, compress="xz", compression_level=9); # save this model
} else
{
  load(file_name);
}

```

The **prior predictive checks** (for the full model) suggest that the priors (using the full model) are a bit biased (especially in what concerns the mean) but they seem decent:
<center>![Prior predictive checks. The observed values (*y*) should fall within the distribution of the simulated priori distribution (*y*~rep~) for the minimum, mean and maximum values.](`r if( !small_HTML ) paste0(worldtree_reg$full$plot_prefix,"_prior_predictive_checks.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

However, the best model seems to be the one including only *rough* and *cfl2* as main effects: the model **converges** well:
<center>![Traces of the Bayesian fitting processes.](`r if( !small_HTML ) paste0(worldtree_reg$notrill$plot_prefix,"_mcmctrace.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>

and the **posterior predictive checks** are very good:
<center>![Posterior predictive checks: density overlays of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(worldtree_reg$notrill$plot_prefix,"_ppcheck_densoverlay.jpg") else "./Image_not_available.jpg"`){width="6in"}</center>
<center>![Posterior predictive checks: minimum, mean and maximum values of the observed (*y*) and simulated (*y*~rep~) data.](`r if( !small_HTML ) paste0(worldtree_reg$notrill$plot_prefix,"_ppcheck_min_mean_max.jpg") else "./Image_not_available.jpg"`){width="4in"}</center>

The estimates of the effects are:
<center>![The estimates of the effects in the 'no trill' model.](`r paste0(worldtree_reg$notrill$plot_prefix,"_mcmcestim.jpg")`){width="6in"}</center>
<center>![The effect of the predictors in the 'no trill' model.](`r paste0(worldtree_reg$notrill$plot_prefix,"_pred.jpg")`){width="4in"}</center>

with their formal hypotheses testing and the 95%HIDs:
```{r results='markup'}
worldtree_reg$notrill$hypotheses;
```

and is better than the null: `r .print.model.comparison(b=worldtree_reg$notrill$cmp_to_null)`.
Please note that even if the effect of *cfl2* seems very close to 0, it does in fact, matter: the model comparison with the model without it: `r .print.model.comparison(b=worldtree_reg$nocfl2$cmp_to_notrill)`.
 

The priors have a very small effect, as shown by their estimates and 95% HDIs below (using the full model):
```{r}
cat("Custom priors:\n"); worldtree_reg$notrill$hdi95;
cat("\n\nDefault priors:\n"); worldtree_reg$notrill_default_priors$hdi95;
```


# Session information

```{r warning=FALSE, results='asis'}
if( require(benchmarkme) )
{
  # CPU:
  cpu_info <- benchmarkme::get_cpu();
  if( is.null(cpu_info) )
  {
    cat("**CPU:** unknown.\n\n");
  } else
  {
    if( !is.null(cpu_info$model_name) && !is.na(cpu_info$model_name) )
    {
      cat(paste0("**CPU:** ",cpu_info$model_name));
      if( !is.null(cpu_info$no_of_cores) && !is.na(cpu_info$no_of_cores) )
      {
        cat(paste0(" (",cpu_info$no_of_cores," threads)"));
      }
      cat("\n\n");
    } else
    {
      cat("**CPU:** unknown.\n\n");
    }
  }
  
  # RAM:
  ram_info <- benchmarkme::get_ram();
  if( is.null(ram_info) || is.na(ram_info) )
  {
    cat("**RAM (memory):** unknown.\n\n");
  } else
  {
    cat("**RAM (memory):** "); print(ram_info); cat("\n");
  }
} else
{
  cat("**RAM (memory):** cannot get info (try installing package 'benchmarkme').\n\n");
}
```

```{r}
pander::pander(sessionInfo());
```



# References
